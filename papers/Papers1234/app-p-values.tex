
\section{Distribution of p-values for all correlations tested}
\label{sec:distr-p-values}

\begin{figure}
  (a)\\
  \includegraphics[width=\linewidth]{figs/p-value-histogram-new-linear}\\
  (b)\\
  \includegraphics[width=\linewidth]{figs/p-value-histogram-new}
  \caption{Histogram of \(p\)-values for all non-parametric 2-sample
    tests listed in Table~\ref{tab:big-p}. (a)~Uniformly spaced linear
    bins and linear vertical axis. (b)~Uniformly spaced logarithmic
    bins and logarithmic vertical axis, with all values
    \(p \le 10^{-6}\) included in the leftmost bin.  Short thin vertical
    lines above the horizontal axis show the individual value.  The
    thick vertical dashed lines shows the traditional threshold values
    for significance: \(p = 0.003\) (\(\approx 3 \sigma\)) and
    \(p = 0.05\) (\(\approx 2 \sigma\)). The red solid line shows the uniform
    distribution of \(p\)-values that would be expected if the null
    hypothesis were always true, that is, if no significant
    correlations existed.}
  \label{fig:histo-p-values}
\end{figure}

\begin{table*}
  \sisetup{detect-all=true, detect-inline-weight=math}
  \sisetup{round-mode=figures, round-precision=2}
  \sisetup{table-align-exponent = false}
  \setlength\tabcolsep{2pt}
  \caption{Results of all statistical tests performed on observed bow
    shock shape parameters. Significant correlations are shown in
    \textbf{bold}, marginally significant correlations in
    \textit{italic}}
  \label{tab:big-p}
  \input{figs/mipsgal-summary-stats-table-body.tex}
\end{table*}

Results from all the statistical tests of the shape distributions
discussed in \S~\ref{sec:corr-shape} are given in
Table~\ref{tab:big-p}.  The \(p\)-values are the probability of
finding a difference between two populations at least as large as what
is observed \emph{given} that there is no difference in the underlying
distribution from which the two populations are drawn (that is, given
that the null hypothesis is true).  Conventionally, the null
hypothesis is rejected at a certain significance threshold \(\alpha\) when
\(p < \alpha\).  Since we are blindly testing many different hypotheses at
once, the commonly used \(\alpha = 0.05\) threshold is too lenient.  In
Figure~\ref{fig:histo-p-values} we analyse the frequency distribution
of \(p\) from all our tests \citep[see][]{Head:2015a}, finding a
systematic excess over a uniform distribution only for \(p < 0.01\).
We therefore take \(\alpha = 0.003\) as the optimum threshold in order to
balance the risks of false positives and false negatives. A false
positive is the erroneous rejection of the null hypothesis (the
spurious detection of a correlation that is not really there), while a
false negative is failing to detect a true correlation.


% However, what we really want to
% know is something else: the probability that the null hypothesis is
% true, \emph{given} the observations.  That is, the probability,
% \(\alpha\), of a \textit{false positive}, also known as the \textit{Type I
%   error rate}.  The common mistake of conflating these two definitions
% is known as the ``\(p\)-value fallacy'' \citep{Goodman:1999a}, or``the
% error of the transposed conditional'', as discussed in detail by
% \citet{Colquhoun:2014a}.  It is possible to derive \(\alpha\) from
% \(p\) using Bayes' theorem (e.g., \citealp{Goodman:1999b}), but that
% requires an estimate of the prior probability of the null hypothesis,
% independent of the observations.  Alternatively, it is also possible
% to find a lower bound on \(\alpha\) from a frequentist approach
% \citep{Sellke:2001a}:
% \begin{equation}
%   \label{eq:type-I}
%   \alpha(p) \ge \bigg[ 1 - \big(e\, p \ln p\big)^{-1} \bigg]^{-1}
%   \quad \text{valid for } p < 1/e.
% \end{equation}
% This is the approach we adopt here, which also numerically coincides
% with the Bayesian approach for the case where the prior probability of
% the null hypothesis is 0.5.  The reason that this is only a lower
% limit for \(\alpha\) is that if we have overwhelming a priori evidence that
% the null hypothesis is true (for instance, from previous empirical
% studies, or because it follows from a well-supported theory), then a
% Bayesian calculation would give a much higher value of \(\alpha\) than
% \eqref{eq:type-I} does.  In our case, however, we have no strong
% reasons for favoring any of the null hypotheses, so it is reasonable
% to assume \(\alpha\) is close to the lower limit given in \eqref{eq:type-I}.

% In order to choose a threshold \(p\)-value that counts as a
% ``significant'' result, one then needs to balance the risks of false
% positives against the risks of \textit{false negatives}.  The false
% negative probability, \(\beta\), also known as \textit{Type II error
%   rate}, is the probability of failing to reject an untrue null
% hypothesis.  That is, in the context of this paper, it is the
% probability of failing to detect a real difference between two
% sub-samples, or a real correlation between two variables.  The
% complementary probability, \(1 - \beta\), is known as the
% \textit{statistical power} or sensitivity of the test.  The value of
% \(\beta\) depends on three factors:
% \begin{enumerate}[1.]
% \item The \textit{effect size}, which is a measure of the magnitude of
%   the difference in a dependent variable between two sub-samples, or
%   the degree of correlation between two continuous variables.  For the
%   two sub-sample case, it is common to use a standardised mean
%   difference, such as Cohen's \(d\) statistic \citep{Cohen:1988a}:
%   \(d = (\bar{X}_A - \bar{X}_B) / s\), where \(\bar{X}_A\),
%   \(\bar{X}_B\) are the means of the dependent variable \(X\) for
%   samples A and B, while \(s\) is the pooled standard deviation of
%   \(X\).  For the case of two continuous variables, the Pearson linear
%   correlation coefficient, \(r\), can be used.  In both cases, rules
%   of thumb have been developed \citep{Ruscio:2008a} for classifying an
%   effect as ``large'' (\(d > 0.8\), \(r > 0.4\)) or ``small''
%   (\(d < 0.2\), \(r < 0.1\)).  Alternatively, non-parametric
%   statistics can be used, such as the \(A\) measure of stochastic
%   superiority \citep{Delaney:2002a}.
% \end{enumerate}

% Obviously, this depends on the \textit{effect size}, which is the 


% All astronomical data analysis is \emph{post hoc} analysis, since the universe was not set up to test a particular hypothesis (as far as we know).  It is therefore important to guard against the ``multiple comparisons problem'', whereby seemingly significant correlations are found where none really exist, simply by virtue of the large number of tests that were carried out.

% Under the more conservative Holm--Bonferroni method, only comparisons with \(p < 0.001\) would be significant. 

% The p-curve \citep{Head:2015a}

% \begin{table}
%   \caption{Results of all statistical tests performed on observed
%     bow shock shape parameters.}
%   \begin{tabular}{p{0.95\linewidth}}
%     \toprule
%     \textit{Description of columns:}
%     (Col.~1)~How the two A/B source sub-samples are defined, also giving the size of each sub-sample, \(n_{\text{A}}\) and~\(n_{\text{B}}\).
%     (Col.~2)~Dependent variable whose distribution is compared between the two sub-samples.
%     (Cols.~3--6)~Mean and standard deviation, \(\sigma\), of the dependent variable for each of the two sub-samples.
%     (Cols.~7--8)~Mean over each sub-sample of the observational dispersion (\(\epsilon\), standard deviation) of radii that contribute to the dependent variable for each individual source, as in steps~\ref{step:R0} and \ref{step:R90} of \S~\ref{sec:autom-trac-fitt}.  Note that in the case of \(R_c\), this is \(\epsilon(R_0)\), and so is not a direct measure of the observational uncertainty in \(R_c\). 
%     (Cols.~9--10)~``Standard error of the mean'' (s.e.m.) of the dependent variable for each of the two sub-samples. 
%     (Cols.~11--13)~Standardized ``effect sizes'', which are dimensionless measures of the difference in the distribution of the dependent variable between the two sub-samples.
%     (Col.~11)~Rank biserial correlation coefficient \citep{Cureton:1956a}, which is obtained by considering all \(n_{\text{A}} n_{\text{B}}\) pair-wise comparisons of the dependent variable between a source in sub-sample~A and a source in sub-sample~B.  It is the difference between the fraction of such comparisons ``won'' by sub-sample~A and those ``won'' by sub-sample~B, and thus may vary between \(-1\) and \(+1\). 
%     (Col.~12)~Cohen's \(d\), which is a dimensionless mean difference: \(d = (\langle \text{A} \rangle - \langle \text{B} \rangle) / \sigma_{\text{pool}} \), where \(\sigma_{\text{pool}} = (n_{\text{A}} \sigma_{\text{A}}^2 + n_{\text{B}} \sigma_{\text{B}}^2)^{1/2} / \sqrt{n_{\text{A}} + n_{\text{B}}}\) is the pooled standard deviation.
%     (Col.~13)~Ratio of standard deviations between the two sub-samples.
%     (Cols.~14--16)~Probabilities (\(p\)-values) of the two sub-samples being as different as observed if they were to be drawn from the same population, according to three different non-parametric tests.
%     (Col.~14)~Anderson--Darling 2-sample test, which is a general test of similarity between two distributions that is designed to retain sensitivity to differences in the tails of the distributions.
%     (Col.~15)~Mann--Whitney--Wilcoxon \(U\) test \citep{Mann:1947a}, which is sensitive to differences in the central value of the distributions.
%     (Col.~16)~Brown--Forsythe test for equality of variance \citep{Brown:1974a}
%     \\
%     \bottomrule
%   \end{tabular}
% \end{table}





\section{Perturbed bow shocks}
\label{sec:perturbed-bows}

\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]{figs/compare_xyprime_wave-wilkinoid}
  \caption{Small-amplitude standing wave perturbations to wilkinoid
    bow shapes.  The maximum deviations from the base shape are seen
    at phases \(\phi = 0\) (blue line) and \(\phi = 0.5\) (red line), while
    the perturbation is zero at \(\phi = 0.25\) and \(0.75\) (black
    line).  Results are shown left to right for increasing wave
    numbers \(N\) and decreasing amplitudes \(A\): (a)~\(A = 0.2\),
    \(N = 1.0\), (b)~\(A = 0.1\), \(N = 2.0\), (a)~\(A = 0.04\),
    \(N = 5.0\).  The maximum curvature, proportional to \(A N\) is
    the same in all three cases.}
  \label{fig:perturb-shapes}
\end{figure*}
\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]
  {figs/wave_xyprime-A010-N20-ancantoid-xi080-beta000500}
  \caption{Plane-of-sky projections of perturbed bow shapes.  In all
    cases, the base bow shape is ancantoid with \(\xi = 0.8\),
    \(\beta = 0.005\) and the perturbation is the curling mode shown in
    the central panel of Fig.~\ref{fig:perturb-shapes}, with amplitude
    \(A = 0.1\) and wave number \(N = 2.0\). Results are shown for
    inclination angles \(i = 0\) to \(i = 75^\circ\) (indicated by line
    color and thickness, see key) and for different fractional phases
    of the oscillation: (a)~\(\varphi = 0.0\), (b)~\(\varphi = 0.25\),
    (c)~\(\varphi = 0.50\). Unlike in Fig.~\ref{fig:perturb-shapes}, the
    spatial coordinates are normalized to the instantaneous projected
    apex radius \(R_0'\) at each phase, so the apex does not appear to
    move.}.
  \label{fig:perturb-xy-prime}
\end{figure*}

In this appendix, we present a highly idealized model for small,
time-varying perturbations to a steady-state bow shock shape, such as
those discussed in \S~5 of Paper~0.  These perturbations may be due to
periodic variations in the momentum-loss rate of one of the winds, or
due to dynamical instabilities in the shocked shell.

We consider fractional perturbations \(\Delta(\theta, t)\) of a base shape
\(R(\theta)\), such that
\(R(\theta) \to [1 + \Delta(\theta, t)] R(\theta)\).  For simplicity,
\(\Delta(\theta, t)\) is a standing wave of constant amplitude \(A\), which is
periodic in \(\theta\), with wave number \(N\).  We assume that the
oscillation occurs simultaneously and coherently at all azimuths, so
that cylindrical symmetry is maintained.  This implies that
\(\Delta(\theta, t)\) must be even in \(\theta\), so can be expressed as
\begin{equation}
  \label{eq:standing-wave}
  \Delta(\theta, t) = A \cos(N \theta) \cos(2\pi \varphi) . 
\end{equation}
For waves with period \(P\), the fractional phase \(\varphi\) will
vary with time \(t\) as
\begin{equation}
  \label{eq:fractional-phase}
  \varphi(t) = (\varphi_0 + t/P) \bmod 1.0\ ,
\end{equation}
where \(\varphi_0\) is an arbitrary reference phase.

Example oscillations with wave numbers \(N = 1.0\), \(2.0\), and
\(5.0\) superimposed on a wilkinoid base shape are shown in
Figure~\ref{fig:perturb-shapes}.  There are \(N\) nodes of the
oscillation between \(\theta = [0, \pi]\), always with an antinode at the apex
(\(\theta = 0\)), as required by symmetry.  So, with \(N = 1.0\) there is a
node (fixed point) in the near wing at \(\theta = \pi/2\), but an antinode in
the far wing at \(\theta = \pi\), which is in antiphase with the oscillation
of the apex, giving rise to a large-scale ``breathing'' mode of
oscillation.  With \(N = 2.0\), there are nodes at \(\theta = \pi/4\) and
\(3\pi/4\), while the antiphase antinode has moved to the near wing at
\(\theta = \pi/2\).  There is still an antinode in the far wing at
\(\theta = \pi\) but it is now in phase with the apex, giving rise to a
``curling-up/straightening-out'' mode of oscillation.  With
\(N = 5.0\), there are many more nodes and antinodes, giving a
``ringing'' mode of oscillation.  Note that all our examples have
\(A \propto 1/N\) in order to keep the local curvature relatively low.  If
the product \(A N\) is not small compared to unity, then the local
curvature can be so extreme as to reverse the concave shape of the
base bow shape, producing locally convex regions.

If the bow shape is viewed at different inclinations, then the effect
of the oscillations on the projected shape will vary.  In particular,
the apex-to-wing interval in body-frame angle changes from
\(\theta = [0, \pi/2]\) at \(i = 0\) to
\(\theta = [\theta_0, \theta_{90}]\) for general \(i\), see equations~(18) and (21)
of Paper~0.  The difference \(\theta_{90} - \theta_0\) is always a declining
function of \(|i|\), so the oscillations of the tangent line become
increasingly stretched out as the inclination increases.  This effect
can be seen in Figure~\ref{fig:perturb-xy-prime}, which shows an
example of the variation in projected perturbed shape with inclination
angle for 3 different phases, this time for an ancantoid base shape
and the \(N = 2.0\) perturbation shown in
Figure~\ref{fig:perturb-shapes}b.  The most marked changes with phase
are seen for low inclinations (light colored lines), whereas the
changes are smaller, although still noticeable, for
\(|i| \ge 45^\circ\). If \(A N\) exceeds about 0.5, then the local curvature
of the perturbations is so extreme that multiple tangent lines exist
at intermediate inclinations, which produces the appearance of
additional incomplete bright arcs inside the main arc of the bow.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "obs-bowshocks"
%%% End:
