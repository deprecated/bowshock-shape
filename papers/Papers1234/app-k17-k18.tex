\section{Covariance of derived quantities from propagation of observational uncertainties}
\label{sec:comb-uncert-covar}

\begin{table}
  \centering
  \caption[Derived]{Propagation of observational uncertainties to derived quantities}
  \label{tab:derived-parameters}
  \setlength\tabcolsep{3pt}
  \begin{tabular}{l S S S S S S}
    \toprule
    \(x_i\) & {\(\sigma_{x_i}\)}
    & {\(J_{x_i} (\tau)\)} & {\(J_{x_i} (\eta\shell)\)}
    & {\(J_{x_i} (\dot M)\)} & {\(J_{x_i} (\dot M_{\text{K18}})\)}
    & {\(J_{x_i} (L_*)\)}
    \\
    \midrule
    \(D\)     & 0.08 & 2  & 3 & 3 & 2 & 0\\
    \(L_*\)   & 0.18 & -1 & -2 & -1 & -0.5 & 1\\
    \(F\IR\)  & 0.12 & 1 & 1 & 1 & 0 & 0\\
    \(I_{70}\) & 0.12 & 0 & 0 & 0 & 1 & 0\\
    \(\theta\) & 0.11 & 0 & 1 & 1 & 2 & 0\\
    \(\ell/R\) & 0.08 & 0 & 0 & 0 & -1 & 0\\
    \(V\wind\) & 0.18 & 0 & 0 & -1 & -1 & 0\\
    \bottomrule
  \end{tabular}
\end{table}



Even though errors in the fundamental observed quantities, \(x_i\),
are assumed independent,\footnote{%
  It is of course true that \(F\IR\) and \(I_{70}\) are not completely
  independent from one another, but this does not matter since we
  consider only derived quantities that are a function of one or the
  other, not both.} %
errors in the derived quantities, \(f_k(x_1, x_2, \dots)\), will not
necessarily be so.  For the purposes of this paper:
\begin{align}
  \label{eq:observed-and-derived}
  x_i \in &  \left\{D;\ L_*;\ F\IR;\ I_{70};\ \theta;\ \ell/R;\ V\wind \right\} \\
  f_k \in & \left\{\tau;\ \eta\shell;\ \dot M;\ \dot M_{\text{K18}};\ L_* \right\}
            \ .
\end{align}
Note that \(L_*\) appears in both lists because we use it as a graph
axis in Figure~\ref{fig:mass-loss-vs-luminosity}.  For the case where
each \(f_k\) is a simple product of powers of the \(x_i\), the
propagation of errors reduces to linear algebra of log
quantities. This is exactly true for \(\tau\) and \(\eta\shell\), but
only approximately so for \(\dot M\) and
\(\dot M_{\text{K18}}\).\footnote{%
  For \(\dot M\) it is true for \(\eta\shell \gg 1.25 \tau\) and for
  \(\dot M_{\text{K18}}\) it is true in the limit that the grain
  emissivity can be expressed as a power law in \(U\).} %
We define \(J_{x_i} (f_k)\) as the elements of the Jacobian matrix of
logarithmic derivatives \(d \ln f_k / d \ln x_i \), which are given
for our quantities in Table~\ref{tab:derived-parameters}.  Then, the
elements of the variance--covariance matrix for the derived parameters
are
\begin{equation}
  \label{eq:covariance}
  C_{k,k'} = \sum_{i} J_{x_i} (f_k) \, \sigma_{x_i}^2 \, J_{x_i} (f_{k'}) \ , 
\end{equation}
where the \(\sigma_{x_i}\) are the rms dispersions in \(x_i\),
measured in dex.  In Figure~\ref{fig:python-covar} we give example
python code for calculating this matrix, using the \(\sigma_{x_i}\)
derived in \S~\ref{sec:distance}--\ref{sec:stell-wind-veloc} for the
K18 sources (second column of Tab.~\ref{tab:derived-parameters}), with
results given in Table~\ref{tab:covariance}.  It can be seen that many
of the off-diagonal elements are of similar magnitude to the diagonal
elements, which is an indication of significant correlations between
the errors in the different parameters.

\begin{table}
  \centering
  \caption[Covariance]{Variance--covariance matrix \(C_{k,k'}\) for derived quantities}
  \label{tab:covariance}
  \setlength\tabcolsep{3pt}
  \begin{tabular}{l S S S S S }
    \toprule
    & {\(\tau\)} & {\(\eta\shell\)}
    & {\(\dot M\)} & {\(\dot M_{\text{K18}}\)} & {\(L_*\)}
    \\
    \midrule
    \(\tau\)               &  0.0724 &  0.1176 &  0.0852 &  0.0418 & -0.0324 \\
    \(\eta\shell\)         &  0.1176 &  0.2137 &  0.1489 &   0.095 & -0.0648 \\
    \(\dot M\)             &  0.0852 &  0.1489 &  0.1489 &  0.1112 & -0.0324 \\
    \(\dot M_{\text{K18}}\)&  0.0418 &   0.095 &  0.1112 &  0.1353 & -0.0162 \\
    \(L_*\)                & -0.0324 & -0.0648 & -0.0324 & -0.0162 &  0.0324 \\
    \bottomrule
  \end{tabular}
\end{table}

For any particular pair of derived quantities, \(f_m\) and \(f_{n}\),
one can find the \textit{error ellipse} that characterises the
projection of observational errors onto the \(f_m\)--\(f_{n}\) plane.
The ellipse is characterized by standard deviations along major and
minor axes, \(\sigma_a\), \(\sigma_b\), together with the angle
\(\theta_a\) between the \(f_m\) axis and the ellipse major axis.
These are given via the eigenvalues and eigenvectors of the relevant
\(2 \times 2\) submatrix of the covariance matrix:
\begin{align}
  \label{eq:error-ellipse}
  \sigma_a^2 = & \frac12 \left\{   C_{m,m} + C_{n,n}
                 + \left[ \left( C_{m,m} + C_{n,n} \right)^2
                 - 4 C_{m,n}^2 \right]^{1/2}\right\} \\
  \sigma_b^2 = & \frac12 \left\{   C_{m,m} + C_{n,n}
                 - \left[ \left( C_{m,m} + C_{n,n} \right)^2
                 - 4 C_{m,n}^2 \right]^{1/2}\right\} \\
  \theta_a = & \frac12 \arctan \left( \frac{2 C_{m,n}}{C_{m,m} - C_{n,n}} \right) \ .
\end{align}
For instance, Table~\ref{tab:error-ellipse} shows the resultant error
ellipse parameters (shown in blue on the respective graphs) for the
relations plotted in Figures~\ref{fig:All-sources-eta-tau},
\ref{fig:mass-loss-vs-luminosity}ab, and
\ref{fig:mass-loss-comparison}.

\begin{table}
  \centering
  \caption[Error ellipse]{Error ellipse parameters for particular pairs of derived quantities}
  \label{tab:error-ellipse}
  \begin{tabular}{l l S S S l}
    \toprule
    \(f_m\) & \(f_n\) &  {\(\sigma_a\)} & {\(\sigma_b\)}
    & {\(\theta_a\), \si{\degree}} & Figure   \\
    \midrule
    \(\tau\) & \(\eta\) & 0.529 & 0.077 & 60.5 & \ref{fig:All-sources-eta-tau} \\
    \(L_*\) & \(\dot M\) & 0.397 & 0.155 & -75.5 & \ref{fig:mass-loss-vs-luminosity}a \\
    \(L_*\) & \(\dot M_{\text{K18}}\) & 0.371 & 0.173 & -81.3 & \ref{fig:mass-loss-vs-luminosity}b \\
    \(\dot M_{\text{K18}}\) & \(\dot M\) & 0.503 & 0.175 & 46.7 & \ref{fig:mass-loss-comparison} \\
    \bottomrule
  \end{tabular}
\end{table}


\begin{figure}
  \centering
  \footnotesize
  \begin{verbatim}
import numpy as np
sig = np.diag([0.08, 0.18, 0.12, 0.12, 0.11, 0.08, 0.18])
J = np.array([
    [2, -1, 1, 0, 0, 0, 0],
    [3, -2, 1, 0, 1, 0, 0],
    [3, -1, 1, 0, 1, 0, -1],
    [2, -0.5, 0, 1, 2, -1, -1],
    [0, 1, 0, 0, 0, 0, 0]
])
C = J @ sig**2 @ J.T
  \end{verbatim}
  \vspace*{-\baselineskip}
  \caption{Snippet of Python code that calculates the
    covariance matrix of Table~\ref{tab:covariance}.  The last line
    implements equation~\eqref{eq:covariance} by a triple matrix
    product of the Jacobian matrix \texttt{J}, the square of a
    diagonal matrix of observational standard deviations \texttt{sig},
    and the transpose of \texttt{J}.}
  \label{fig:python-covar}
\end{figure}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "bs-bw-dw-03"
%%% End:
