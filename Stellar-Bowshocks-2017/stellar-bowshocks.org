* Bowshocks around moving OB and RSG stars
** Nature of arcs around O stars
+ There is some question whether they are really bow shocks, or are instead dust waves.
  + Example of the latter is 
** Previous work on theory of projected shapes
*** Cox et al 2012
+ Have a reasonably sane discussion of the projection of the /Wilkinoid/ shape
+ Consider R_0 and R_90
+ 
** Observations of O star bow shocks 
+ Use Kubulnicky (2016), who have 709 objects!
+ Best observations are 24 micron Spitzer MIPSGAL images
*** Catalog of Kobulnicky bow shocks 
+ [[file:OB/Kobulnicky2016/table1.dat]]
*** How to get the images of OB bow shocks
+ Loop through the table and do searches on the coordinates
  + Follow the API described at http://irsa.ipac.caltech.edu/applications/Atlas/AtlasProgramInterface.html
  + The example given for MIPSGAL is
    + http://irsa.ipac.caltech.edu/cgi-bin/Atlas/nph-atlas?mission=MIPSGAL&locstr=NGC+6631&regSize=12.5&covers=on&mode=PI
    + But we would be best off using coordinates
    + As in =&locstr=17h18m57s+60d21m12s=
  + We could probably use the =requests= python library for that
    + It looks very easy to use
    + Relevant example code from the [[http://docs.python-requests.org/en/master/user/quickstart/][documentation]]
      #+BEGIN_SRC python
        payload = {'key1': 'value1', 'key2': 'value2'}
        r = requests.get('http://httpbin.org/get', params=payload)
      #+END_SRC
  + This gives an XML file that will contain a line like this
    #+BEGIN_SRC xml
      <result status="ok">
      <description>
      <collection>MIPSGAL</collection>
      <ra>276.813000</ra>
      <dec>-12.020000</dec>
      <regSize>12.500000</regSize>
      <radius>6.250000</radius>
      <radunits>degrees</radunits>
      </description>
      <coverageMap>
      <resultHtml>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/index.html
      </resultHtml>
      <resultMap>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/region.jpg
      </resultMap>
      <resultFits>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/background_IRAS_ISSA_12micron.fits
      </resultFits>
      </coverageMap>
      <summary>
      <counts>
      <imagesN>12</imagesN>
      <sourcesN>0</sourcesN>
      <spectraN>0</spectraN>
      </counts>
      <downloadScript>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/wget_data.bat
      </downloadScript>
      <dataTag>ADS/IRSA.Atlas#2017/0303/205546_3307</dataTag>
      </summary>
      <images>
      <counts>12</counts>
      <metadata>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/images.tbl
      </metadata>
      <metadataVOtable>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/images.xml
      </metadataVOtable>
      </images>
      </result>
    #+END_SRC
  + Then you can grab for example the =wwget_data.bat= file
    + Although the url is bad, since it should be https instead of http
  + And that will give you something like this
    #+BEGIN_SRC sh 
      #!/bin/sh
      #
      # To run as an executable on a unix platform, do the following:
      # chmod 775 wget_data.bat
      # ./wget_data.bat
      #
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/compcubes/MG0200n005_024_compcube.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/compcubes/MG0190n005_024_compcube.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/residual/residual_MG0190n005_024_all.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/residual/residual_MG0200n005_024_all.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_maskcube_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_maskcube_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_std_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_std_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_covg_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_covg_024.fits"

    #+END_SRC
  + Alternatively, the images.xml table has the list of FITS images and associated metadata as a VOTable
  + Or the images.tbl has it as a simple table
  + Either should be readable with astropy
**** Download all the MIPS 24 micron images
#+BEGIN_SRC sh
mkdir -pv OB/MipsGal
#+END_SRC


#+BEGIN_SRC python :eval no :tangle mipsgal-image-stamps.py
  import os
  import sys
  import requests
  import xmltodict
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  import astropy.units as u
  import astropy.coordinates as coord

  SST_URL = 'http://irsa.ipac.caltech.edu/cgi-bin/Atlas/nph-atlas'
  mipsgal_params = {
      'mission': 'MIPSGAL',
      'mode': 'PI',
      'regSize': '0.01',
      'covers': 'on',
  }
  IMG_URL_ROOT = 'https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL'

  SOURCE_DIR = 'OB/Kobulnicky2016'
  source_table = Table.read(
      os.path.join(SOURCE_DIR, 'table1.dat'),
      format='ascii.cds',
      readme=os.path.join(SOURCE_DIR, 'ReadMe')
  )

  OUTPUT_IMAGE_DIR = 'OB/MipsGal'
  IMAGE_SIZE_DEGREES = 4.0/60.0           

  def skycoord_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{data['DE-']}{data['DEd']} {data['DEm']} {data['DEs']}"
      return coord.SkyCoord(f'{ra} {dec}', unit=(u.hourangle, u.deg))

  try:
      k1 = int(sys.argv[1])
  except:
      k1 = None
  try:
      k2 = int(sys.argv[2])
  except:
      k2 = None

  # Loop over all sources in the table
  for source_data in source_table[k1:k2]:
      # Make a SkyCoord object
      c = skycoord_from_table_row(source_data)
      # Perform a search around the specified coordinates
      r = requests.get(SST_URL,
                       params={**mipsgal_params, 'locstr': c.to_string()})

      # Extract the URL of the table of images (if present)
      try:
          img_tbl_url = xmltodict.parse(r.content)['result']['images']['metadata']
      except KeyError:
          # Probably a source without Spitzer observations
          continue
      # Need to switch to https and grab the file
      r2 = requests.get(img_tbl_url.replace('http:', 'https:'))
      # We need to remove the first line from the table so that it can be parsed
      table_lines = r2.content.decode().split('\n')[1:]
      # Then read it in as another astropy table
      img_table = Table.read(table_lines, format='ascii')

      # Select out all the images that are mosaic science images
      mosaic_images = {}
      for img_row in img_table:
          fname = img_row['fname']
          m_id = fname.split('/')[-1].split('_')[0]
          if img_row['file_type'] == 'science' and 'mosaics24' in fname:
              mosaic_images[m_id] = os.path.join(IMG_URL_ROOT, fname)

      # Now make postage stamps of all the selected images
      for m_id in mosaic_images:
          hdu = fits.open(mosaic_images[m_id])[0]
          w = WCS(hdu)
          # pixel coord of source
          i0, j0 = np.round(c.to_pixel(w))
          # find pixel limits of cut-out image window around source
          xpix_scale, ypix_scale = np.abs(w.wcs.cdelt)
          di = np.round(0.5*IMAGE_SIZE_DEGREES/xpix_scale)
          dj = np.round(0.5*IMAGE_SIZE_DEGREES/ypix_scale)
          win = slice(int(j0 - dj), int(j0 + dj)), slice(int(i0 - di), int(i0 + di))
          # Construct a new HDU
          hdr_win = w.slice(win).to_header()
          for k in 'Seq', 'Name', 'R0', 'PA':
              hdr_win[k] = source_data[k]
          hdr_win['MIPSGAL'] = m_id
          hdr_win['ORIGURL'] = mosaic_images[m_id]
          imwin = fits.PrimaryHDU(
              data=hdu.data[win],
              header=hdr_win)
          # Construct a suitable file name
          imid = f"{source_data['Seq']:04d}-{source_data['Name']}-{m_id}"
          imfn = os.path.join(OUTPUT_IMAGE_DIR, f'{imid}.fits')
          imwin.writeto(imfn, overwrite=True)
#+END_SRC
*** DONE How to trace the shapes of the OB bow shocks
CLOSED: [2017-03-28 Tue 13:24]
+ Strategy is to start at the nominal PA of the bowshock axis and take radial slices
  + Maybe fit a Gaussian brightness as function of radius for each \theta
  + calculate \theta and R for each pixel
  + use \theta \pm d\theta/2 to construct a mask over all the pixels
  + where d\theta is the interval between radii
    + say, d\theta = 5\deg perhaps
+ We can stop when we have got to \pm45\deg or maybe \pm60\deg and then calculate the radius of curvature and a better estimate for the symmetry axis
  + Then we do it again, but with radii drawn from the center of curvature that we have just determined
  + We can call this angle \theta_c
  + The idea is that we are best off taking slices that are close to normal to the bowshock, so that we can get out to \theta = \pm 90\deg if we are lucky
+ [X] Note that at some point I might want to use "sky offset" frames - see documentation for =astropy.coordinates=
+ [X] Improvements to make [2017-03-09 Thu]
  + [X] Add a vector to image to show nominal axis PA
  + [X] Indicate which cases have doubt about the central star
  + [X] Use the =OVERRIDE= dict for sources with bad data
  + [X] Try taking a longer step-back distance (maybe twice R0)
  + [X] Add the \pm90 vertical lines to the graphs
  + [X] (/ABANDONED/) Mask out the stars
    + Either detect point sources
    + Or, download the 8 micron images
  + [X] Do the Rc and R90 fits
  + [X] (/ABANDONED/) Deal with cases where the object dows not fit in the box:
    + 534, 542
+ List of the nicest sources
  + 001 - Rc/R0 = 0.8, R90/R0 = 1.4 (misidentified source)
  + 018 - Rc/R0 = 1.26, R90/R0 = 1.7 in hyperbola zone
  + 056 - Rc/R0 = 2.8, R90/R0 = 1.9 in the oblate zone
  + 060 - Smallish example of Rc/R0 ~= 1, R90/R0 ~= 2
  + 087 - On the circle curve for Rc/R0 = 2.5
  + 123 - Beautiful case of Rc/R0 = 1.42 and R90/R0 = 1.72
  + 127 - Another nice case of Rc/R0 = 2
  + 133 - small and flat
  + 274 - good pointed wings
  + 285 - nice open wings
  + 292 - big and flat, but asymmetric wings
  + 433 - small with triangular wings
  + 440 - small but well-formed
  + 442 - nice and pointy, circular
  + 447 - flat nose with tucked in wings
  + 489 - Closely circular with Rc/R0 = 1.25
  + 491 - Similar to 489
  + 509 - big flat thing
  + 530 - smaller pointy one
  + 595 - nice pointy wings
  + 598 - textbook example of Rc/R0 = 2
  + 634 - big cometary shape
  + 635 - flatter and big
  + 667 - nice curvy one
  + 677, 678 - these two overlap
#+BEGIN_SRC python :eval no :tangle mipsgal-trace-arc.py
  import glob
  import os
  from collections import OrderedDict
  import numpy as np
  from astropy.table import Table, QTable
  from astropy.io import fits
  from astropy.wcs import WCS
  import astropy.units as u
  import astropy.coordinates as coord
  from astropy.visualization.wcsaxes import SphericalCircle
  from matplotlib import pyplot as plt
  import seaborn as sns
  import circle_fit_utils

  sns.set_style('white')


  SOURCE_DIR = 'OB/Kobulnicky2016'
  source_table = Table.read(
      os.path.join(SOURCE_DIR, 'table1.dat'),
      format='ascii.cds',
      readme=os.path.join(SOURCE_DIR, 'ReadMe')
  )

  IMAGE_DIR = 'OB/MipsGal'

  ENVIRONMENTS = {
      'I': 'Isolated',
      'H': 'H II region',
      'FH': 'Facing H II region',
      'FB': 'Facing bright-rimmed cloud',
  }


  # Some data in the the Kobulnicky2016 table is just wrong
  OVERRIDE = {
      8: {'R0': 5.0},
      10: {'R0': 16.0},
      85: {'R0': 20.0},
      228: {'R0': 18.0},
      648: {'R0': 40},
      650: {'R0': 50},
  }
  STEP_BACK_FACTOR = 2.0
  CIRCLE_THETA = 45.0*u.deg

  THMIN, THMAX = coord.Angle([-160.0*u.deg, 160.0*u.deg])

  def description_from_table_row(data):
      desc = data['Name'] + '\n'
      if data['Alias']:
          desc += data['Alias'] + '\n'
      desc += f"R0 = {data['R0']:.1f} arcsec, PA = {data['PA']} deg" + '\n'
      csource = 'Multiple candidates' if data['Unc'] == 'C' else 'Single candidate'
      desc += f'{csource} for central source' + '\n'
      desc += f"Environment: {ENVIRONMENTS[data['Env']]}"
      return desc


  def skycoord_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{data['DE-']}{data['DEd']} {data['DEm']} {data['DEs']}"
      return coord.SkyCoord(f'{ra} {dec}', unit=(u.hourangle, u.deg))


  def coord_concat(array_tuple, **kwds):
      """Like numpy.concatenate but ensures result is of coordinate type"""
      return coord.SkyCoord(np.concatenate(array_tuple, **kwds))


  for source_data in source_table:

      print(source_data)
      # Override data from table where necessary
      if source_data['Seq'] in OVERRIDE:
          for k, v in OVERRIDE[source_data['Seq']].items():
              source_data[k] = v

      # Coordinates of source central star
      c = skycoord_from_table_row(source_data)
      # Find all the images for this source
      provisional_list = glob.glob(
          f"{IMAGE_DIR}/*-{source_data['Name']}-*.fits")
      # Look for an image that is good
      good_image_list = []
      for image_name in provisional_list:
          hdu, = fits.open(image_name)
          looks_good = hdu.header['NAXIS1'] == hdu.header['NAXIS2']
          if looks_good:
              good_image_list.append(image_name)

      if good_image_list:
          # Use the first one in the list - because: why not? 
          hdu, = fits.open(good_image_list[0])
      else:
          # If there were no good images, then never mind
          continue

      # Create WCS object for this image
      w = WCS(hdu)
      # Find celestial coordinates for each pixel
      ny, nx = hdu.data.shape
      xpix = np.arange(nx)[None, :]
      ypix = np.arange(ny)[:, None]
      cpix = coord.SkyCoord.from_pixel(xpix, ypix, w)
      # Now find radius and position angle from source
      rpix = c.separation(cpix).to(u.arcsec)
      pa_pix = c.position_angle(cpix).to(u.degree)
      # Nominal PA of bowshock axis from table
      pa0 = coord.Angle(source_data['PA'], unit=u.degree)
      # theta is angle from nominal axis, set to range [-180:180]
      theta_pix = coord.Longitude(pa_pix - pa0, wrap_angle=180*u.degree)

      # Also create an offset frame in case we need it later, in which
      # measurements are with respect to the central source coordinate,
      # and rotated by pa0
      offset_frame = c.skyoffset_frame(rotation=pa0)
      # Coordinates of each pixel in the offset frame - this has
      # components: offset_pix.lat (along pa0) and offset_pix.lon
      # (perpendicular to pa0)
      offset_pix = cpix.transform_to(offset_frame)

      # Nominal arc radius from source table
      R0 = source_data['R0']*u.arcsec

      # Only look in a restricted range of radius around R0
      rad_mask = (rpix > 0.5*R0) & (rpix < 3.0*R0)

      # Minimum and median brightness, which we might need later
      bright_min = np.nanmin(hdu.data)
      bright_median = np.nanmedian(hdu.data)

      # Next, we trace the arc

      # 08 Mar 2017 - Try a different tack - take radii from a center
      # that is "stepped back" by STEP_BACK_FACTOR times R0 away from
      # the source
      c_sb = coord.SkyCoord(0.0*u.deg, -STEP_BACK_FACTOR*R0,
                            frame=offset_frame).transform_to('icrs')
      # Repeat all the above to find radius, angle from this new point
      # Now find radius and position angle from source
      r_sb_pix = c_sb.separation(cpix).to(u.arcsec)
      pa_sb_pix = c_sb.position_angle(cpix).to(u.degree)
      # theta is angle from nominal axis, set to range [-180:180]
      th_sb_pix = coord.Longitude(pa_sb_pix - pa0, wrap_angle=180*u.degree)
      # And a frame relative to the "step back" center too
      sb_offset_frame = c_sb.skyoffset_frame(rotation=pa0)


      # Loop over a grid of angles between +/- 60 degrees
      ntheta = 51
      theta_grid, dtheta = np.linspace(-60.0, 60.0, ntheta, retstep=True)
      # Make everything be a longitude in range [-180:180]
      th_sb_grid = coord.Longitude(theta_grid, unit=u.degree, wrap_angle=180*u.degree)
      dtheta = coord.Longitude(dtheta, unit=u.degree, wrap_angle=180*u.degree)
      r_sb_peak_grid = []
      r_sb_mean_grid = []
      bmax_grid = []
      bmean_grid = []
      for th_sb in th_sb_grid:
          # Select only pixels in the wedge within +/- dtheta/2 of this theta
          theta_mask = np.abs(th_sb_pix - th_sb) < 0.5*dtheta
          # Combine with the radius mask
          m = theta_mask & rad_mask

          if np.alltrue(~m):
              # If mask is empty, fill in this theta with NaNs
              r_sb_peak = np.nan*u.deg
              r_sb_mean = np.nan*u.deg
              bright_max = np.nan
              bmean = np.nan
          else:            
              # Try a variety of methods for determining the arc radius
              # at this theta ...

              # Peak brightness
              ipeak = hdu.data[m].argmax()
              r_sb_peak = r_sb_pix[m][ipeak]

              # Mean brightness-weighted radius. We divide weights by
              # radius to compensate for density of pixels. Also, we
              # select only points brighter than 0.5 times the peak
              # brightness in this wedge.  And all brightnesses are
              # relative to a background floor, which is either the
              # median over the whole image or, if the peak in the wedge
              # is lower than that, then the minimum over the image
              bright_max = hdu.data[m].max()
              bright_floor = bright_median if bright_max > bright_median else bright_min
              mb = (hdu.data - bright_floor) > 0.5*(bright_max - bright_floor)
              weights = (hdu.data[m & mb] - bright_floor)/r_sb_pix[m & mb]
              try: 
                  r_sb_mean = np.average(r_sb_pix[m & mb], weights=weights)*u.arcsec
                  bmean = np.average(hdu.data[m & mb], weights=weights)
              except ZeroDivisionError:
                  r_sb_mean = np.nan*u.deg
                  bmean = np.nan

          # Fit Gaussian to profile - TODO?

          # Save all quantities into grid lists
          r_sb_mean_grid.append(r_sb_mean)
          r_sb_peak_grid.append(r_sb_peak)
          bmax_grid.append(bright_max)
          bmean_grid.append(bmean)

      # convert to single array of each quantity
      r_sb_mean_grid = coord.Angle(r_sb_mean_grid)
      r_sb_peak_grid = coord.Angle(r_sb_peak_grid)
      bmax_grid = np.array(bmax_grid)
      bmean_grid = np.array(bmean_grid)


      # Now switch back to the frame centered on the source

      # Get the arc coordinates in RA, Dec
      #
      # Use the offset frame centered on the source and aligned with PA
      # axis.  The order of components is (lon, lat) where lon is
      # perpendicular and lat parallel to the bowshock axis
      rmean_coords = coord.SkyCoord(
          r_sb_mean_grid*np.sin(th_sb_grid),
          r_sb_mean_grid*np.cos(th_sb_grid),
          frame=sb_offset_frame).transform_to('icrs')
      rpeak_coords = coord.SkyCoord(
          r_sb_peak_grid*np.sin(th_sb_grid),
          r_sb_peak_grid*np.cos(th_sb_grid),
          frame=sb_offset_frame).transform_to('icrs')

      # Switch back to frame centered on source
      rmean_grid = c.separation(rmean_coords).to(u.arcsec)
      theta_mean_grid = coord.Longitude(
          c.position_angle(rmean_coords).to(u.degree) - pa0,
          wrap_angle=180*u.degree)
      rpeak_grid = c.separation(rpeak_coords).to(u.arcsec)
      theta_peak_grid = coord.Longitude(
          c.position_angle(rpeak_coords).to(u.degree) - pa0,
          wrap_angle=180*u.degree)

      # Fit circle to peak points within CIRCLE_THETA of axis
      cmask_peak = np.abs(theta_peak_grid) <= CIRCLE_THETA
      cmask_mean = np.abs(theta_mean_grid) <= CIRCLE_THETA
      # Use the mean and peak points
      try: 
          points2fit = coord_concat((rpeak_coords[cmask_peak],
                                     rmean_coords[cmask_mean]))
          # Winnow out the points with radii too far from median
          r2fit = c.separation(points2fit).to(u.arcsec)
          rmed = np.median(r2fit)
          print('Median radius for circle fit:', rmed)
          mfit = (r2fit >= 0.5*rmed) & (r2fit <= 2.0*rmed)
          n_drop = (~mfit).sum()
          if n_drop > 0:
              print(n_drop, 'points dropped for circle fit')
          points2fit = points2fit[mfit]
          # Initial guess for center would make Rc/R0 = 2
          center0 = coord.SkyCoord(0.0*u.deg, -R0,
                                   frame=offset_frame).transform_to('icrs')
          Rc, center = circle_fit_utils.fit_circle(points2fit, center0)
          Rc = Rc.to(u.arcsec)
      except:
          print('ABORT - Problem with points2fit or circle_fit_utils.fit_circle')
          continue


      if Rc > 100*R0:
          print('ABORT due to ridiculous radius of curvature: Rc =', Rc)
          continue

      # Find standard deviation of points from circle
      Rc_sigma = np.std(
          circle_fit_utils.deviation_from_circle(points2fit, center)
      ).to(u.arcsec)

      # Find PA of circle fit
      # First assume case where center of curvature is "behind" the source
      pa_circ = center.position_angle(c).to(u.deg)
      # Find difference between fitted and nominal position angle
      delta_pa = coord.Longitude(pa_circ - pa0, wrap_angle=180*u.deg)
      if np.abs(delta_pa) > 90*u.deg:
          # Check for Case where center of curvature is "in front of" the source
          pa_circ = c.position_angle(center).to(u.deg)
          delta_pa = coord.Longitude(pa_circ - pa0, wrap_angle=180*u.deg)

      # Find our estimate of R0
      #
      # Make some masks selecting points within 10 deg of pa_circ
      m0_peak = np.abs(theta_peak_grid - delta_pa) <= 10.0*u.deg
      m0_mean = np.abs(theta_mean_grid - delta_pa) <= 10.0*u.deg
      # Then concatenate all the R values that meet this condition
      R0_grid = coord.Angle(
          np.concatenate((rpeak_grid.value[m0_peak],
                          rmean_grid.value[m0_mean])),
          unit=u.arcsec)
      R0_fit, R0_sigma = R0_grid.mean(), R0_grid.std()
      fit_msg = f'Fitted R0 = {R0_fit.arcsec:.1f} +/- {R0_sigma.arcsec:.1f} arcsec' + '\n'

      # Make an offset frame centered on the center of curvature
      circ_offset_frame = center.skyoffset_frame(rotation=pa_circ)
      # Find R(theta) for the fitted circle
      thdash = np.linspace(-180.0, 180.0, 501)*u.deg
      circ_points = coord.SkyCoord(
          Rc*np.sin(thdash), Rc*np.cos(thdash),
          frame=circ_offset_frame).transform_to('icrs')
      circ_theta = coord.Longitude(
          c.position_angle(circ_points).to(u.deg) - pa0,
          wrap_angle=180*u.degree)
      circ_radius = c.separation(circ_points).to(u.arcsec)
      # Eliminate points that are not within +/- 100 deg of nominal axis
      mcirc = (circ_theta >= -100.0*u.deg) & (circ_theta <= 100.0*u.deg)
      circ_radius[~mcirc] *= np.nan
      fit_msg += f'PA_circ = {pa_circ.deg:.1f}, delta PA = {delta_pa.deg:.1f}' + '\n'
      fit_msg += f'Rc = {Rc.arcsec:.1f} +/- {Rc_sigma.arcsec:.1f} arcsec' + '\n'

      # Find R90
      #
      # Make some masks selecting points within 10 deg of +90 and -90
      m90p_peak = np.abs(theta_peak_grid - 90.0*u.deg) <= 10.0*u.deg
      m90n_peak = np.abs(theta_peak_grid + 90.0*u.deg) <= 10.0*u.deg
      m90p_mean = np.abs(theta_mean_grid - 90.0*u.deg) <= 10.0*u.deg
      m90n_mean = np.abs(theta_mean_grid + 90.0*u.deg) <= 10.0*u.deg
      # Then concatenate all the R values for the two cases
      R90p_grid = coord.Angle(
          np.concatenate((rpeak_grid.value[m90p_peak],
                          rmean_grid.value[m90p_mean])),
          unit=u.arcsec)
      R90n_grid = coord.Angle(
          np.concatenate((rpeak_grid.value[m90n_peak],
                          rmean_grid.value[m90n_mean])),
          unit=u.arcsec)
      # And calculate mean and standard deviation
      R90p, R90p_sigma = R90p_grid.mean(), R90p_grid.std()
      R90n, R90n_sigma = R90n_grid.mean(), R90n_grid.std()
      fit_msg += f'R90+ = {R90p.arcsec:.1f} +/- {R90p_sigma.arcsec:.1f} arcsec' + '\n'
      fit_msg += f'R90- = {R90n.arcsec:.1f} +/- {R90n_sigma.arcsec:.1f} arcsec' + '\n'


      # Save the fit data for each source
      table_file_name = image_name.replace('.fits', '-arcfit.tab')
      save_vars = [
          ['Seq', source_data['Seq']], 
          ['R0_fit', R0_fit.arcsec], 
          ['R0_sigma', R0_sigma.arcsec],
          ['pa_circ', pa_circ.deg],
          ['delta_pa', delta_pa.deg],
          ['Rc', Rc.arcsec],
          ['Rc_sigma', Rc_sigma.arcsec],
          ['R90p', R90p.arcsec],
          ['R90p_sigma', R90p_sigma.arcsec],
          ['R90n', R90n.arcsec],
          ['R90n_sigma', R90n_sigma.arcsec],
      ]
      colnames, colvals = zip(*save_vars)
      Table(rows=[list(colvals)],
            names=list(colnames)).write(table_file_name,
					format='ascii.tab',
					overwrite=True)

      # Save a figure for each source
      fig = plt.figure(figsize=(12, 8))

      # Make a plot of the radii and brightnesses versus theta
      ax_r = fig.add_axes((0.08, 0.55, 0.35, 0.4))
      ax_b = fig.add_axes((0.08, 0.08, 0.35, 0.4))
      ax_i = fig.add_axes((0.5, 0.1, 0.45, 0.45), projection=w)
      ax_r.plot(theta_mean_grid, rmean_grid, 'o', c='c', label='mean')
      ax_r.plot(theta_peak_grid, rpeak_grid, 'o', c='r', label='peak')
      ax_r.plot(circ_theta, circ_radius,
		'--', c='m', label='circle fit')
      ax_r.axhline(R0.value)
      ax_r.axvspan(-90.0, 90.0, facecolor='k', alpha=0.05)
      ax_r.axvspan(-CIRCLE_THETA.value, CIRCLE_THETA.value, facecolor='k', alpha=0.05)
      ax_r.axvline(0.0, c='k', ls='--')
      ax_r.legend()
      ax_r.set(xlim=[THMIN.deg, THMAX.deg],
               ylim=[0.0, None], ylabel='Bow shock radius, arcsec')
      ax_b.plot(theta_mean_grid, bmean_grid - bright_median, 'o', c='c', label='mean')
      ax_b.plot(theta_peak_grid, bmax_grid - bright_median, 'o', c='r', label='peak')
      ax_b.axvspan(-90.0, 90.0, facecolor='k', alpha=0.05)
      ax_b.axvspan(-CIRCLE_THETA.value, CIRCLE_THETA.value, facecolor='k', alpha=0.05)
      ax_b.axvline(0.0, c='k', ls='--')
      ax_b.legend()
      ax_b.set(xlim=[THMIN.deg, THMAX.deg], xlabel='Angle from nominal axis, degree',
               ylim=[0.0, None], ylabel='Bow shock brightness',
      )

      # And also plot the image
      ax_i.imshow(hdu.data,
                  vmin=bright_min, vmax=bmean_grid.max(), origin='lower')

      # And contours
      if bmax_grid.max() > bright_median:
          clevels = np.linspace(bright_median, bmax_grid.max(), 10)
      else:
          clevels = np.linspace(bright_median, hdu.data.max(), 10)
      ax_i.contour(hdu.data, levels=clevels, alpha=0.5)

      wtran = ax_i.get_transform('world')

      # Add markers for the traced bow shock
      ax_i.scatter(rmean_coords.ra.deg, rmean_coords.dec.deg, transform=wtran,
                   marker='.', c='c', s=30, alpha=0.5)
      ax_i.scatter(rpeak_coords.ra.deg, rpeak_coords.dec.deg, transform=wtran,
                   marker='.', c='r', s=30, alpha=0.5)

      # Add a line for the PA orientation
      PA_coords = coord.SkyCoord(
          [0.0*u.deg, 0.0*u.deg], [-2*R0, 2*R0],
          frame=offset_frame).transform_to('icrs')
      ax_i.plot(PA_coords.ra.deg, PA_coords.dec.deg,
		transform=wtran, c='orange', lw=2, alpha=0.8)

      # And plot the fitted circle
      circ = SphericalCircle((center.ra, center.dec), Rc,
                             edgecolor='m', lw=2, alpha=0.5, facecolor='none',
                             transform=wtran)
      ax_i.add_patch(circ)
      # And a line for the fitted PA axis
      PA_fit_coords = coord.SkyCoord(
          [0.0*u.deg, 0.0*u.deg], [-1.2*Rc, 1.2*Rc],
          frame=circ_offset_frame).transform_to('icrs')
      ax_i.plot(PA_fit_coords.ra.deg, PA_fit_coords.dec.deg,
		transform=wtran, c='m', lw=1.5, alpha=0.6)
      # And the center of curvature
      ax_i.scatter(center.ra.deg, center.dec.deg, transform=wtran,
                   marker='o', s=30, edgecolor='k', facecolor='m')
      # Add a marker for the source
      ax_i.scatter(c.ra.deg, c.dec.deg, transform=wtran,
                   s=150, marker='*', edgecolor='k', facecolor='orange')


      # Add coordinate grids
      ax_i.coords.grid(color='m', linestyle='solid', alpha=0.2)
      ax_i.coords['ra'].set_axislabel('Right Ascension')
      ax_i.coords['dec'].set_axislabel('Declination')
      overlay = ax_i.get_coords_overlay('galactic')
      overlay.grid(color='c', linestyle='solid', alpha=0.2)
      overlay['l'].set_axislabel('Galactic Longitude')
      overlay['b'].set_axislabel('Galactic Latitude')

      # Add title
      ax_i.text(0.5, 1.7, description_from_table_row(source_data),
		transform=ax_i.transAxes, ha='center', va='bottom'
      )
      ax_i.text(0.5, 1.6, fit_msg,
		transform=ax_i.transAxes, ha='center', va='top'
      )

      fig.savefig(image_name.replace('.fits', '-multiplot.png'))
      # Important to close figure explicitly so as not to leak resources
      plt.close(fig)

#+END_SRC
**** Updated routines for circle fitting
+ Updated version of [[file:~/Work/Bowshocks/Jorge/bowshock-shape/read-shapes-LL/fit-circle-shell.py]]
+ Main difference is that we work in sky coordinates
  + =astropy.coords.SkyCoord=
#+BEGIN_SRC python :eval no :tangle circle_fit_utils.py
  import numpy as np
  import astropy.coordinates as coord
  import astropy.units as u
  import lmfit

  def Rc_from_data(points, center):
      return np.mean(center.separation(points))

  def deviation_from_circle(points, center):
      return center.separation(points) - Rc_from_data(points, center)

  def model_minus_data(params, points):
      center = coord.SkyCoord(params["ra"].value*u.deg, params["dec"].value*u.deg)
      return deviation_from_circle(points, center).arcsec

  def fit_circle(points, center0):
      """Fit a circle to `points` with initial guess that center is at
  `center0`.  Returns radius of curvature and center of curvature"""
      params = lmfit.Parameters()
      params.add("ra", value=center0.ra.deg)
      params.add("dec", value=center0.dec.deg)
      out = lmfit.minimize(model_minus_data, params, args=(points,))
      lmfit.report_fit(out)
      center = coord.SkyCoord(out.params["ra"].value*u.deg, out.params["dec"].value*u.deg)
      Rc = Rc_from_data(points, center)
      return Rc, center

#+END_SRC
**** Combining the fit data into one table
#+BEGIN_SRC python :results file :return combo_file
  import os
  import glob
  from astropy.table import Table, join

  SOURCE_DIR = 'OB/Kobulnicky2016'
  source_table = Table.read(
      os.path.join(SOURCE_DIR, 'table1.dat'),
      format='ascii.cds',
      readme=os.path.join(SOURCE_DIR, 'ReadMe')
  )

  IMAGE_DIR = 'OB/MipsGal'

  list_of_rows = []
  tabfiles = glob.glob(f"{IMAGE_DIR}/*-arcfit.tab")
  for tabfile in tabfiles:
      t = Table.read(tabfile, format='ascii.tab')
      list_of_rows.append(t[0])

  fit_table = Table(rows=list_of_rows, names=t.colnames)
  star_table = Table.read('star-ratings.tab', format='ascii.tab')

  combo_table = join(
      join(source_table, fit_table, join_type='outer'),
      star_table, join_type='outer')


  combo_file = 'mipsgal-arcfit.tab'
  combo_table.write(combo_file, format='ascii.tab', overwrite=True)
#+END_SRC

#+RESULTS:
[[file:mipsgal-arcfit.tab]]

*** Plot the radius ratio diagnostics for the OB bowshocks
First, radius versus radius
#+BEGIN_SRC python :return figfile :results file
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-r0-r0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = (m1 | m2), m3, m4, m5
  alphas = 0.05, 0.3, 0.5, 0.8
  labels = '1- or 2-star', '3-star', '4-star', '5-star'
  colors = 'k', 'c', 'r', 'b'
  sizes = 3, 5, 7, 10


  for m, alpha, c, ms, label in zip(masks, alphas, colors, sizes, labels):
      ax.errorbar('R0', 'R0_fit', yerr='R0_sigma', data=tab[m],
                  fmt='o', lw=1, c=c, ms=ms, alpha=alpha,
                  label=f'{label} ($N = {m.sum()}$)')
  ax.plot([1.0, 200.0], [1.0, 200.0])
  ax.axhline(5.5, 0.0, 0.55, ls=':', lw=1, color='k')
  ax.legend()
  ax.set(
      xlim=[2, 110], ylim=[2, 110],
      xlabel='Catalog $R_0$, arcsec',
      ylabel='Fitted $R_0$, arcsec',
      xscale='log', yscale='log')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-r0-r0.pdf]]

And now, Rc versus R90
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')

  figfile = 'mipsgal-Rc-R90.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2)
                              + 0.5*(tab['R90p'] - tab['R90n'])**2)

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m1 = Q > 50.0
  m2 = (Q > 20.0) & ~m1
  m3 = (Q > 5.0)  & ~(m1 | m2)
  m4 = ~(m1 | m2 | m3)

  masks = m4, m3, m2, m1
  alphas = 0.1, 0.2, 0.4, 0.8
  labels = 'Q <= 5', 'Q > 5', 'Q > 20', 'Q > 50'


  for m, alpha, label in zip(masks, alphas, labels):
      ax.errorbar('Rc', 'R90', xerr='Rc_sigma', yerr='R90_sigma', data=tab[m],
                  fmt='.', lw=1, alpha=alpha, label=label)
  ax.plot([0.0, 100.0], [0.0, 100.0])
  ax.legend()
  ax.set(
      xlim=[0.1, 100.0], ylim=[0.1, 100.0],
      xlabel='Radius of curvature ratio: Rc/R0',
      ylabel='Perpendicular radius ratio: R90/R0',
      xscale='log', yscale='log')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90.pdf]]

Zoom in on the best data
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-zoom.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  Q = tab['R0_fit']/tab['R0_sigma']

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = m3, m4, m5
  alphas = 0.2, 0.4, 0.8
  stars = '3', '4', '5'
  colors = 'c', 'r', 'b'
  sizes = 5, 7, 10

  for m, alpha, star, c, ms in zip(masks, alphas, stars, colors, sizes):
      label = f'{star}-star ($N = {m.sum()}$)'
      ax.errorbar('Rc', 'R90', xerr='Rc_sigma', yerr='R90_sigma', data=tab[m],
                  fmt='o', ms=ms, lw=1, alpha=alpha, c=c, label=label)
      ax.errorbar('Rc', 'R90', yerr='R90_asym', data=tab[m],
                  fmt='none', elinewidth=0.5, alpha=alpha, ecolor=c, label=None)
      # ax.errorbar('Rcp', 'R90p', xerr='Rc_sigma', yerr='R90p_sigma', data=tab[m],
      #             fmt='o', lw=1, alpha=alpha, c=c, label=label)
      # ax.errorbar('Rcn', 'R90n', xerr='Rc_sigma', yerr='R90n_sigma', data=tab[m],
      #             fmt='s', lw=1, alpha=alpha, c=c, label=None)

  for source in tab[m5]:
      ax.text(source['Rc'], source['R90'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')
  for source in tab[m4 & (tab['Rc'] < 1.0)]:
      ax.text(source['Rc'], source['R90'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')

  ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-zoom.pdf]]

Plot KDE of the distribution


#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-kde.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = m3, (m4 | m5)
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma in zip(masks, alphas, cmaps, shades, gammas):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)



  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-kde.pdf]]

+ This figure is modified using Graphic.app to add thumbnail images of selected bow shocks
+ The result is exported in [[file:mipsgal-Rc-R90-thumbnails.pdf]]


*** Histograms of differences in PA
+ This is not that informative 
+ [X] Maybe include it as an inset to the R_0-R_0 graph
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-delta-PA.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  fig, axes = plt.subplots(3, 1, figsize=(3.5, 4), sharex=True)

  masks = m3, m4, m5
  colors = 'c', 'r', 'b'
  labels = '3-star', '4-star', '5-star'

  x1, x2 = -105.0, 105.0
  for ax, m, c, label in zip(axes, masks, colors, labels):
      sigma = np.nanstd(tab['delta_pa'][m])
      sns.distplot(tab['delta_pa'][m], kde=False,
                   bins=15, hist_kws={'range': [x1, x2]},
                   ax=ax, color=c,
                   label=fr'{label}' + '\n' + fr'$\sigma = {sigma:.0f}^\circ$')
      ax.axvline(0.0, c='k', ls='--', alpha=0.4)
      ax.legend(fontsize='x-small')
      ax.set(xlabel='', xlim=[x1, x2])
      sns.despine(ax=ax, trim=True)

  axes[-1].set(
      xlabel='PA difference: (fitted $-$ catalog), degrees',
      ylabel='Number of sources',
  )
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-delta-PA.pdf]]

*** AB testing of various sub-sets

**** H II region versus isolated
+ So this show the various 'Env' types:
  + I :: /Isolated/ in purple filled contours
  + FB,FH :: /Facing bright rim/ or /Facing H II region/ as solid orange contours
  + H :: Inside /H II region/ as dashed green contours
+ Result is that there is very little difference

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-environment.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  misolated = tab['Env'] == 'I'
  mfacing = (tab['Env'] == 'FH') | (tab['Env'] == 'FB')
  mhii = tab['Env'] == 'H'

  masks = misolated & mgood, mfacing & mgood, mhii & mgood
  shades = True, False, False
  alphas = 0.8, 0.8, 0.8
  cmaps = 'Purples', 'Oranges_d', 'Greens_d'
  gammas = 0.5, 0.5, 0.5
  lss = None, 'solid', 'dashed'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.25, 0.15),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)


  masks5 = misolated & m5, mfacing & m5, mhii & m5
  colors = 'purple', 'orange', 'g'
  alphas = 0.8, 0.8, 0.8
  labels = 'Isolated', 'Facing', 'H II region'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Bow shock\nEnvironment')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.06
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_i_Rc = fig.add_axes((subwin_x0,
                              subwin_y0 + 2*(subwin_h + subwin_ymargin),
                              subwin_w, subwin_h))
      ax_f_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_h_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_i_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + 2*(subwin_h + subwin_ymargin),
                               subwin_w, subwin_h))
      ax_f_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_h_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      yq0, dyq = 0.15, 0.05
      for m, c, axx in zip(masks, colors, [ax_i_Rc, ax_f_Rc, ax_h_Rc]):
          sns.distplot(tab['Rc'][m], bins=10, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 7), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S and A-D statistics
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]], midrank=False)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_h_Rc.set(xlabel=r'$R_c/R_0$')
      for axx in ax_i_Rc, ax_f_Rc:
          axx.set(xlabel='')
          axx.tick_params(labelbottom='off') 

      for m, c, axx in zip(masks, colors, [ax_i_R90, ax_f_R90, ax_h_R90]):
          sns.distplot(tab['R90'][m], bins=10, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 7), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]], midrank=False)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_h_R90.set(xlabel=r'$R_{90}/R_0$')
      for axx in ax_i_R90, ax_f_R90:
          axx.set(xlabel='')
          axx.tick_params(labelbottom='off') 


  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-environment.pdf]]


**** Single vesus multiple candidates for central source
+ This is the "Unc" column in the table
+ The idea is the ones with "C" have an aditional uncertainty in R_0, which could move points along diagonal lines through the origin
  + Actually not quite that, since R90 would be affected too
+ *Results:* There is no difference between the two samples at all
  + This implies that errors in R_0 due to uncertainty in identifying the stellar source are not important.
+ [X] Add marginal distribution histograms
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-candidates.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  mmultiple = tab['Unc'] == 'C'
  msingle = ~mmultiple

  masks = mmultiple & mgood, msingle & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Greens', 'Oranges_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = mmultiple & m5, msingle & m5
  colors = 'g', 'orange'
  alphas = 0.8, 0.8
  labels = 'Multiple', 'Single'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Source\nCandidates')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.01


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_m_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_s_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_m_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_s_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_m_Rc, ax_s_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]], midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_s_Rc.set(xlabel=r'$R_c/R_0$')
      ax_m_Rc.set(xlabel=None)
      ax_m_Rc.tick_params(labelbottom='off') 

      for m, c, axx in zip(masks, colors, [ax_m_R90, ax_s_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]], midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_s_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_m_R90.set(xlabel=None)
      ax_m_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-candidates.pdf]]

**** With or without 8 micron emission
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from scipy.stats import ks_2samp, anderson_ksamp
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-8micron.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  myes = tab['8um'] == 'Y'
  mno = tab['8um'] == 'N'

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Oranges', 'Greens_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'orange', 'g'
  alphas = 0.8, 0.8
  labels = 'Yes', 'No'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='8 micron\nEmission?')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.01


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel=None)
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel=None)
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-8micron.pdf]]

**** Correlation with extinction
+ This seems to be the only case, where there might be something there
  + The distribution of R_c is slightly broader for the low-extinction sub-sample
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-extinction.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  Ak_median = np.nanmedian(tab['Ak'][mgood])

  myes = tab['Ak'] >= Ak_median
  mno = tab['Ak'] < Ak_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Reds', 'Blues_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'c'
  alphas = 0.8, 0.8
  labels = fr'$A_K > {Ak_median:.1f}$', fr'$A_K < {Ak_median:.1f}$'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Extinction')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-extinction.pdf]]


**** Correlation with R_0
+ Finally, a highly significant correlation!
+ Larger sources tend to have a higher Rc/R0 (with p=0.005) and (especially) a higher R90/R0 (with p=0.0001)
+ We need to bear in mind that this might possibly be an observational artifact
  + Since the smaller arcs tend to have lower star ratings
  + But I don't think this is the (whole) answer
+ More convincing is the fact that both R0 and Rc/R0 and R90/R0 tend to increase with inclination
  + At least this is true for hyperbolic-type shapes
+ Also worht noting that the observed effect is opposite to what would be expected due to errors in determining R_0
  + In that case you would have larger R_0 producing smaller ratios (and vixe versa)
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, mannwhitneyu
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  def rank_biserial(a, b):
      U = mannwhitneyu(a, b, alternative='two-sided')
      rb = 1.0 - 2*U.statistic/(len(a)*len(b))
      return rb, U.pvalue

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-R0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  R0_median = np.nanmedian(tab[R0var][mgood])

  myes = tab[R0var] >= R0_median
  mno = tab[R0var] < R0_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.3],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'c', 'r'
  alphas = 0.8, 0.8
  labels = fr"$R_0 > {R0_median:.1f}''$", fr"$R_0 < {R0_median:.1f}''$"

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Bow shock\nangular size')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              s = fr'A-D $p = {pAD:.4f}$'
              rb, pMW = rank_biserial(tab['Rc'][m], tab['Rc'][masks[0]])
              s += '\n' + fr'$r_b = {rb:.2f}$'
              axx.text(1.0, 0.9, s,
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
            
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {np.sum(m)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              s = fr'A-D $p = {pAD:.4f}$'
              rb, pMW = rank_biserial(tab['R90'][m], tab['R90'][masks[0]])
              s += '\n' + fr'$r_b = {rb:.2f}$'
              axx.text(1.0, 0.9, s,
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-R0.pdf]]


***** DONE Do the same, but only for 4-star sources
CLOSED: [2017-03-20 Mon 14:01]
+ This gives nothing significant, so best to forget it
+ And the sign of the effect is opposite to that with the full sample!
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-R0-4star.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m4

  R0_median = np.nanmedian(tab['R0_fit'][mgood])

  myes = tab['R0'] >= R0_median
  mno = tab['R0'] < R0_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.3],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'c', 'r'
  alphas = 0.8, 0.8
  labels = fr"$R_0 > {R0_median:.1f}''$", fr"$R_0 < {R0_median:.1f}''$"

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Bow shock\nangular size')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)



#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-R0-4star.pdf]]

***** Look directly at joint distributions of R_0 and the radial ratios
+ These turn out not to be very illuminating
+ The previous graphs are much better
+ [2017-04-06 Thu] But now repurposed to show the change in dispersion of R90 with R0 

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr, linregress
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns
  import statsmodels.api as sm

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])
  tab['dR90'] = np.abs(tab['R90p'] - tab['R90n'])/tab['R90']

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, (ax, axr, axa) = plt.subplots(3, 1, sharex=True, figsize=(6, 9))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  cmap = 'Reds'
  gamma = 0.5
  # sns.kdeplot(np.log10(tab[R0var][mgood].data), tab['R90'][mgood].data,
  #             cmap=cmap, n_levels=10, #bw=0.04,
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  R0_median = np.nanmedian(tab[R0var][mgood])
  mbig = tab[R0var] > R0_median
  msmall = ~mbig

  xvar = np.array(np.log10(tab[R0var].data))
  yvar = np.array(tab['R90'].data)

  # Linear regression: y = a x + b
  # This does the Pearson r at the same time
  a, b, r, p, da = linregress(np.log10(tab[R0var][mgood].data), tab['R90'][mgood].data)
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  # ax.text(0.95, -0.05, s,
  #         fontsize='x-small', color='b',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='right', va='bottom', transform=ax.transAxes)
  xgrid = np.linspace(np.nanmin(xvar[mgood]), np.nanmax(xvar[mgood]))
  x0 = np.nanmean(np.log10(tab[R0var][mgood].data))
  ax.annotate(s=s, 
              xy=(xgrid[-10], a*xgrid[-10] + b),
              xytext=(0.95, -0.05), textcoords='axes fraction',
              arrowprops={'arrowstyle': '-|>', 'color': 'b'},
              fontsize='x-small', color='b',
              bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
              ha='right', va='bottom')
  ax.fill_between(xgrid,
                  a*x0 + (a+da)*(xgrid - x0) + b,
                  a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.4)
  ax.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':')
  #sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False, lowess=True, ax=ax)
  #sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False, truncate=True, robust=True,n_boot=100, color='m', ax=ax)



  # Do residuals
  residuals = tab['R90'].data - a*np.log10(tab[R0var].data) - b
  yvar = np.array(np.abs(residuals))
  # sns.kdeplot(np.log10(tab[R0var][mgood].data), yvar[mgood],
  #             cmap=cmap, n_levels=10, #bw=0.04,
  #             shade=True, shade_lowest=False, ax=axr, alpha=0.8)

  # Linear regression on the residuals: y = a x + b
  # This does the Pearson r at the same time
  a, b, r, p, da = linregress(xvar[mgood], yvar[mgood])
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  # axr.text(0.02, 1.05, s,
  #          fontsize='x-small', color='b',
  #          bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #          ha='left', va='top', transform=axr.transAxes)
  xgrid = np.linspace(np.nanmin(xvar[mgood]), np.nanmax(xvar[mgood]))
  x0 = np.nanmean(np.log10(tab[R0var][mgood].data))
  axr.annotate(s=s, 
           xy=(xgrid[7], a*xgrid[7] + b),
           xytext=(0.02, 1.05), textcoords='axes fraction',
           arrowprops={'arrowstyle': '-|>', 'color': 'b'},
           fontsize='x-small', color='b',
           bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
           ha='left', va='top')
  axr.fill_between(xgrid,
                   a*x0 + (a+da)*(xgrid - x0) + b,
                   a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.4)
  axr.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':')

  lowess = sm.nonparametric.lowess(yvar[mgood], xvar[mgood], frac=0.8)
  axr.plot(lowess[:, 0], lowess[:, 1], lw=4, ls='--', alpha=0.7, color='g')
  s = 'LOWESS regression'
  axr.annotate(
      s=s, xy=(lowess[223,0], lowess[223,1]),
      xycoords='data', color='g',
      xytext=(1.6, -0.1), textcoords='data', fontsize='x-small',
      arrowprops={'arrowstyle': '-|>', 'color': 'g'},
      ha='center', va='center')

  # Based on the LOWESS result, redo the linear regression for log10(R0) < 1.4
  mfit = mgood & (xvar <= 1.4)
  a, b, r, p, da = linregress(xvar[mfit], yvar[mfit])
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  xgrid = np.linspace(np.nanmin(xvar[mgood]), 1.4)
  x0 = np.nanmean(np.log10(tab[R0var][mfit].data))
  axr.annotate(s=s, 
           xy=(xgrid[4], a*xgrid[4] + b),
           xytext=(0.05, 0.05), textcoords='axes fraction',
           arrowprops={'arrowstyle': '-|>', 'color': 'r'},
           fontsize='x-small', color='r',
           bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
           ha='left', va='top')
  axr.fill_between(xgrid,
                   a*x0 + (a+da)*(xgrid - x0) + b,
                   a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.2, color='r')
  axr.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':', color='r')



  # sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False,
  #             line_kws=dict(color='orange', alpha=0.5, ls='--', lw=4),
  #             lowess=True, ax=axr)
  #sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False, truncate=True, robust=True, n_boot=100, color='m', ax=axr)

  # Do the asymmetry in R90
  yvar2 = np.array(tab['dR90'].data)
  # Linear regression on the residuals: y = a x + b
  # This does the Pearson r at the same time
  a, b, r, p, da = linregress(xvar[mgood], yvar2[mgood])
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  xgrid = np.linspace(np.nanmin(xvar[mgood]), np.nanmax(xvar[mgood]))
  x0 = np.nanmean(np.log10(tab[R0var][mgood].data))
  axa.annotate(s=s, 
           xy=(xgrid[4], a*xgrid[4] + b),
           xytext=(0.05, 0.95), textcoords='axes fraction',
           arrowprops={'arrowstyle': '-|>', 'color': 'b'},
           fontsize='x-small', color='b',
           bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
           ha='left', va='top')
  axa.fill_between(xgrid,
                   a*x0 + (a+da)*(xgrid - x0) + b,
                   a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.4)
  axa.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':')

  # sns.regplot(x=xvar[mgood], y=yvar2[mgood], scatter=False,
  #             line_kws=dict(color='g', alpha=0.5, ls='--', lw=2),
  #             lowess=True, ax=axa)



  # AD, levelsAD, pAD = anderson_ksamp(
  #     [tab['R90'][mgood & msmall], tab['R90'][mgood & mbig]],
  #     midrank=False)
  # ax.text(0.5, 0.9, fr'A-D $p = {pAD:.4f}$',
  #     fontsize='x-small',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='center', va='top', transform=ax.transAxes)

  # q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][mgood & msmall],
  #                                            [10, 25, 50, 75, 90])
  # s = f'R0 < {R0_median:.2f}'
  # s += '\n' + f'# of sources: {(mgood & msmall).sum()}'
  # s += '\n' + f'Median: {q50:.2f}'
  # s += '\n' + f'Quartiles: {q25:.2f}, {q75:.2f}'
  # s += '\n' + f'Deciles: {q10:.2f}, {q90:.2f}'
  # ax.text(0.1, 0.9, s,
  #     fontsize='x-small',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='left', va='top', transform=ax.transAxes)

  # q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][mgood & mbig],
  #                                            [10, 25, 50, 75, 90])
  # s = f'R0 > {R0_median:.2f}'
  # s += '\n' + f'# of sources: {(mgood & mbig).sum()}'
  # s += '\n' + f'Median: {q50:.2f}'
  # s += '\n' + f'Quartiles: {q25:.2f}, {q75:.2f}'
  # s += '\n' + f'Deciles: {q10:.2f}, {q90:.2f}'
  # ax.text(0.9, 0.9, s,
  #     fontsize='x-small',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='right', va='top', transform=ax.transAxes)



  masks = m3, m4, m5
  alphas = 0.3, 0.4, 0.5
  stars = '3', '4', '5'
  colors = 'c', 'c', 'c'
  sizes = 5, 7, 8

  for m, alpha, star, c, ms in zip(masks, alphas, stars, colors, sizes):
      label = f'{star}-star ($N = {m.sum()}$)'
      ax.plot(np.log10(tab[R0var][m].data), tab['R90'][m].data,  'o',
              ms=ms, lw=1, alpha=alpha, c=c, label=label)
      axr.plot(np.log10(tab[R0var][m].data), yvar[m],  'o',
               ms=ms, lw=1, alpha=alpha, c='m', label=label)
      axa.plot(np.log10(tab[R0var][m].data), yvar2[m],  'o',
               ms=ms, lw=1, alpha=alpha, c='r', label=label)
  # ax.axvline(np.log10(np.nanmedian(tab[R0var][mgood])), color='k')




  ax.set(
      xlim=[0.65, 1.85], ylim=[0.55, 2.9],
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$')
  axr.set(
      ylim=[-0.08, 0.78],
      ylabel=r'Absolute residual from $R_{90}/R_0$ regression')
  axa.set(
      # ylim=[-0.08, 0.78],
      xlabel=r'Axial radius: $\log_{10}\, R_0$',
      ylabel=r'$|R_{90+} - R_{90-}| / R_{90}$')


  sns.despine(trim=True)
  sns.despine(ax=ax, bottom=True)
  sns.despine(ax=axr, bottom=True)
  fig.tight_layout()
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf]]

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-ratio-versus-R0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3
  
  cmap = 'Greens'
  gamma = 0.5
  sns.kdeplot(np.log10(tab['R0_fit'][mgood].data), tab['Rc'][mgood].data,
              cmap=cmap, n_levels=30,
              shade=True, shade_lowest=False, ax=ax, alpha=0.8)

              
  masks = m3, m4, m5
  alphas = 0.2, 0.4, 0.8
  stars = '3', '4', '5'
  colors = 'c', 'r', 'b'
  sizes = 5, 7, 8

  for m, alpha, star, c, ms in zip(masks, alphas, stars, colors, sizes):
      label = f'{star}-star ($N = {m.sum()}$)'
      ax.plot(np.log10(tab['R0_fit'][m].data), tab['Rc'][m].data,  'o',
              ms=ms, lw=1, alpha=alpha, c=c, label=label)

  ax.axvline(np.log10(np.nanmedian(tab['R0_fit'][mgood])), color='k')

  ax.set(
      xlim=[0.7, 1.7], ylim=[0., 5.0],
      xlabel=r'Axial radius: $\log_{10} R_0$',
      ylabel=r'Radius of cuvature ratio: $R_{c}/R_0$',
      xscale='linear', yscale='linear')



  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-ratio-versus-R0.pdf]]


***** Try a finer 5-bin quantization of R_0 and H_0

+ [X] Also, calculate the 5-sample A-D statistic
+ [X] And add in the wing asymmetry factor |R_{90+} - R_{90-}| / R_90
  + This is about 0.2
+ [X] Try tests of heteroscedasticity
  + White's Lagrange Multiplier Test =statsmodels.stats.diagnostic.het_white()=
  + Or just do a Pearson-r on the absolute deviations
  + Finally plumped for Brown--Forsythe variant of Levene test
+ [X] Add in the observational =R90_sigma=

#+BEGIN_SRC python :results file :return figfile
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-boxplot-Rc-R90-versus-R0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'
  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])
  tab['dR90'] = np.abs(tab['R90p'] - tab['R90n'])/tab['R90']
  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )

  fig, axes = plt.subplots(5, 1, sharex=True, figsize=(3, 8))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # Make some box plots by discretizing the R_0 axis
  logR0 = np.log10(tab[R0var][mgood].data)
  n = len(logR0)
  # Sort R0 into ascending bins with 30 sources per bin
  sort_order = np.argsort(logR0)
  R0_rank = np.empty_like(logR0)
  R0_rank[sort_order] = np.arange(n)
  # R0_rank = np.searchsorted(np.sort(logR0), logR0)
  R0_bins = R0_rank//46
  R0_label = np.zeros_like(R0_bins).astype('U3')
  for ibin in set(R0_bins):
      mbin = R0_bins == ibin
      R0_label[mbin] = int(10**np.nanmedian(logR0[mbin]))

  #R0_label = (2*np.round(logR0/2, 1)).astype('U3')
  R0_order = sorted(set(R0_label), key=float)

  for ax, Rshape in zip(axes, ['R90', 'Rc', 'dR90', 'R90_sigma', R0var]):
      sns.boxplot(x=R0_label, y=tab[Rshape][mgood], order=R0_order, ax=ax)
      if Rshape != R0var:
          # Anderson-Darling k-sample test over the 5 sub-samples
          AD, levelsAD, pAD = anderson_ksamp(
              [tab[Rshape][mgood][R0_label == _] for _ in R0_order],
              midrank=False)
          if pAD > 0.01:
              s = f'A-D $p = {pAD:.3f}$'
          else:
              pexp = np.floor(np.log10(pAD))
              s = rf'A-D $p = {pAD/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
          ax.text(0.1, -0.04, s,
                  ha='left', va='top', transform=ax.transAxes,
                  fontsize='x-small'
          )


  axes[0].set(ylabel=r'$R_{90} / R_{0}$', ylim=[0.0, None])
  axes[1].set(ylabel=r'$R_{c} / R_{0}$', ylim=[0.0, 5.0])
  axes[2].set(ylabel=r'$|R_{90+} - R_{90-}|/ R_{90}$',
              ylim=[-0.01, None], yticks=[0, 0.2, 0.8])
  axes[3].set(ylabel=r'$\sigma (R_{90}) / R_{0}$',
              ylim=[-0.01, None], yticks=[0, 0.2, 0.8])
  axes[4].set(ylabel=r"$R_0$, $''$", yscale='log', ylim=[None, 200.0])
  for iR0, R0_median in enumerate(R0_order):
      x = (iR0 + 0.5) / len(R0_order)
      axes[-1].text(x, 1.0, f'$N = {np.sum(R0_label == R0_median)}$',
                    ha='center', va='top', transform=ax.transAxes,
                    fontsize='xx-small'
      )
  axes[-1].set(xlabel=r"Sub-sample median $R_0$, $''$", )
  sns.despine(trim=True)
  for ax in axes[:-1]:
      sns.despine(ax=ax, bottom=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-boxplot-Rc-R90-versus-R0.pdf]]

Try the same with H_0

#+BEGIN_SRC python :results file :return figfile
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-boxplot-Rc-R90-versus-H0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])
  tab['dR90'] = np.abs(tab['R90p'] - tab['R90n'])/tab['R90']
  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )

  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  fig, axes = plt.subplots(5, 1, sharex=True, figsize=(3, 8))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # Make some box plots by discretizing the R_0 axis
  H0 = tab['Hmag'][mgood].data
  n = len(H0)
  # Sort R0 into ascending bins with 30 sources per bin
  sort_order = np.argsort(H0)
  H0_rank = np.empty_like(H0)
  H0_rank[sort_order] = np.arange(n)
  # R0_rank = np.searchsorted(np.sort(logR0), logR0)
  H0_bins = (n - 1 - H0_rank)//46
  H0_label = np.zeros_like(H0_bins).astype('U4')
  for ibin in set(H0_bins):
      mbin = H0_bins == ibin
      H0_label[mbin] = np.nanmedian(H0[mbin])

  #R0_label = (2*np.round(logR0/2, 1)).astype('U3')
  H0_order = sorted(set(H0_label), key=float)[::-1]

  for ax, Rshape in zip(axes, ['R90', 'Rc', 'dR90', 'R90_sigma', 'Hmag']):
      sns.boxplot(x=H0_label, y=tab[Rshape][mgood], order=H0_order, ax=ax)
      if Rshape != 'Hmag':
          # Anderson-Darling k-sample test over the 5 sub-samples
          AD, levelsAD, pAD = anderson_ksamp(
              [tab[Rshape][mgood][H0_label == _] for _ in H0_order],
              midrank=False)
          if pAD > 0.01:
              s = f'A-D $p = {pAD:.3f}$'
          else:
              pexp = np.floor(np.log10(pAD))
              s = rf'A-D $p = {pAD/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
          ax.text(0.1, -0.04, s,
                  ha='left', va='top', transform=ax.transAxes,
                  fontsize='x-small'
          )
  axes[0].set(ylabel=r'$R_{90} / R_{0}$', ylim=[0.0, None])
  axes[1].set(ylabel=r'$R_{c} / R_{0}$', ylim=[0.0, 5.0])
  axes[2].set(ylabel=r'$|R_{90+} - R_{90-}|/ R_{90}$', ylim=[-0.01, None], yticks=[0, 0.2, 0.8])
  axes[3].set(ylabel=r'$\sigma (R_{90}) / R_{0}$',
              ylim=[-0.01, None], yticks=[0, 0.2, 0.8])
  axes[4].set(ylabel=r'$H_0$, mag', ylim=[4.5, 13.9], yticks=[6, 9, 12])
  for iH0, H0_median in enumerate(H0_order):
      x = (iH0 + 0.5) / len(H0_order)
      axes[-1].text(x, 1.0, f'$N = {np.sum(H0_label == H0_median)}$',
                    ha='center', va='top', transform=ax.transAxes,
                    fontsize='xx-small'
      )
  axes[-1].set(xlabel=r"Sub-sample median $H_0$, mag", )
  sns.despine(trim=True)
  for ax in axes[:-1]:
      sns.despine(ax=ax, bottom=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-boxplot-Rc-R90-versus-H0.pdf]]





**** DONE Stellar magnitude
CLOSED: [2017-03-20 Mon 11:31]
+ Another marginal correlation:
  + Brighter sources tend to have larger Rc and R90
  + But we only have p=0.1 or so, so doesn't meet the formal significance requirement 
+ [X] Need to re-do this to use the extinction-corrected distances
  + It will be interesting to see if the correlation is better or worse that the one with R_0
  + If it is worse, then it is indirect evidence that it is the non-distance component of the R_0 variation that is responsible for the correlation with shape
+ So it turns out that the correlation is now significant for R_90 although only marginally so for R_c
  + This would perhaps be consistent with it being intrinsic source luminosity that is influencing the shape
    + More luminous sources have more open wings
  + Alternatively, it could be a distance effect
  + It would argue against it being inclination that is causing the R_0-shape correlation
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-Mag.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  MH_median = np.nanmedian(tab['Hmag'][mgood])

  myes = tab['Hmag'] <= MH_median
  mno = tab['Hmag'] > MH_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Oranges', 'Greens_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.3],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'g'
  alphas = 0.8, 0.8
  labels = (fr"$H < {MH_median:.1f}$",
            fr"$H > {MH_median:.1f}$")

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Source\nMagnitude')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-Mag.pdf]]

**** DONE Galactic longitude and latitude
CLOSED: [2017-03-20 Mon 14:22]
+ Use |b| for distance of sight line from plane
+ And cos(l) for distance of sight line from Galactic Center
+ Turns out that there are no significant correlations with either
  + Especially not with longitude
***** Correlation with log_10|b|
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  import astropy.units as u
  import astropy.coordinates as coord
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-cos-glat.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')
  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  bmedian = np.nanmedian(tab['log10 |b|'][mgood])

  myes = tab['log10 |b|'] >= bmedian
  mno = tab['log10 |b|'] < bmedian

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Reds', 'Blues_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'c'
  alphas = 0.8, 0.8
  labels = fr"$|b| > {10**bmedian:.1f}^\circ$", fr"$|b| < {10**bmedian:.1f}^\circ$"

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Galactic latitude')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-cos-glat.pdf]]

***** Correlation with cos(l)
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  import astropy.units as u
  import astropy.coordinates as coord
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-cos-glon.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')
  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # cosl_median = np.nanmedian(tab['cos(l)'][mgood])
  cosl_median = 0.8

  myes = tab['cos(l)'] >= cosl_median
  mno = tab['cos(l)'] < cosl_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Reds', 'Blues_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'c'
  alphas = 0.8, 0.8
  labels = fr'$\cos(\ell) > {cosl_median:.1f}$', fr'$\cos(\ell) < {cosl_median:.1f}$'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Galactic\nlongitude')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-cos-glon.pdf]]


**** Reddening and extinction
:PROPERTIES:
:ID:       12C6A97A-CA32-4404-9E51-58B7E84401CF
:END:
+ The reddening is simply calculated from the (H - [4.5]) color excess
+ This follows Majewski et al (2011)
+ It is very simple because most stars are in the Rayleigh--Jeans limit by the H-band, so that there is little spread in the intrinsic (H - [4.5])_0 color
+ In Majewski, they assume (H - [4.5])_0 = 0.08 for all stars
  + But we could maybe improve on that by using a value more tailored for OB stars
+ And use the Indebetouw (2005) reddening law
  + There you can see why (H - [4.5]) is the best color to use
    + Blueward of H (e.g., J), the intrinsic color variation of the stars is a lot greater
    + Redward of 4.5 microns, you start to run into variations between different dust models (and scatter between different lines of sight too), and then the silicate absorption feature at 10 microns comes in as well
  + So Inbetouw give results in terms of A_{[\lambda]} /A_K (averages over 3 regions)
    | Band  |     \lambda | A_{[\lambda]} /A_K    |
    |-------+-------+-------------|
    | J     | 1.240 | 2.50 \pm 0.15 |
    | H     | 1.664 | 1.55 \pm 0.08 |
    | K     | 2.164 | 1.00        |
    | [3.6] | 3.545 | 0.56 \pm 0.06 |
    | [4.5] | 4.442 | 0.43 \pm 0.08 |
    | [5.8] | 5.675 | 0.43 \pm 0.10 |
    | [8.0] | 7.760 | 0.43 \pm 0.10 |
  + And they don't determine A_V/A_K themselves, but that varies from 8.8 (R_V = 3.3) to 7.5 (R_v = 5)
+ This leads Majewski to the formula:
  + A_K = 0.918 (H - [4.5] - 0.08)
  + So the 0.08 is (H - [4.5])_0
  + And the 0.918 factor should be
    + 1/(A_H/A_K - A_{[4.5]}/A_K)
    + = 1/(1.55 \pm 0.08 - 0.43 \pm 0.08)
    + = 0.893 +/- 0.090
    + Which is not quite the same, but well within the uncertainties, which are of order 10%
  + Perhaps the difference is due to them using K_s instead of K
  + And (H - [4.5])_0 varies between about -0.2 for the earliest O stars, up to about -0.05 for the B stars.  By definition, it is 0.0 for A0 stars
  + So, taking -0.1 would be more realistic than +0.08, which will shift the zero point slightly
+ [X] So I can recalculate A_K using the formula:
  + A_K = (0.893 \pm 0.090) (H - [4.5] + 0.1)
+ [X] And then find the corrected stellar magnitude as:
  + H_0 = H - (1.55 \pm 0.08) A_K

**** DONE Multifactor pair plot of the non-shape parameters
CLOSED: [2017-03-20 Mon 10:48]
+ Use =seaborn.pairplot()= to make a grid of regression plots
+ Or =seaborn.PairGrid()= for finer control
+ Note that the sample is only our fitted bow shocks, so doesn't include the non-Spitzer sources
  + This means that it is all sources in the inner Galaxy
+ Note that Kobulnicky's Fig 8 and Fig 9 are reproduced (approximately) in the top-left and top-right corners of the grid
+ We give extinction-corrected magnitudes H_0
  + We re-derived the extinction using a slightly bluer intrinsic color, more suitable for OB stars (see [[id:12C6A97A-CA32-4404-9E51-58B7E84401CF][Reddening and extinction]])
    + This makes alost no difference, except it eliminates some of the apparent small negative extinctions
    + Main uncertainty is due to variations in the IR extinction curve, which give approx 10% uncertainty in A_K
+ /Things that we find:/
  1. Clearest correlation is between size and H_0, which is probably due to distance of the source
     - This has r = -0.43
       + Implying that about 20% of the variance in in size is "explained" by variation in H_0
     - H band magnitudes of Trapezium, etc
       | Star     | Sp Type |     H |  A_V |    D |    M_H |
       |----------+---------+-------+-----+------+-------|
       | \theta^1 C     | O7 V    |  4.63 |   1 |  400 | -3.58 |
       | \theta^1 B     | B3 V    |   6.3 |   1 |  400 | -1.91 |
       | \theta^1 A     | B0 V    |   5.8 |   1 |  400 | -2.41 |
       | \theta^1 D     | B1.5 V  |  5.89 |   1 |  400 | -2.32 |
       | \theta^2 A     | O9.5 IV |  4.97 | 0.2 |  400 | -3.08 |
       | \theta^2 B     | B2-B5 V |  6.27 | 0.2 |  400 | -1.78 |
       |----------+---------+-------+-----+------+-------|
       | HD 93129 | O2 I    |  6.14 |   1 | 2300 | -5.87 |
       | \zeta Pup    | O4 I    |   2.9 |   0 |  330 | -4.69 |
       | \lambda Cep    | O6.5 I  | 4.618 |   0 |  600 | -4.27 |
       | UW CMa   | O7 I    |  5.19 |   0 |  580 | -3.63 |
       | 19 Cep   | O9 Ib   |  4.92 |   0 | 1200 | -5.48 |
       | \alpha Cam    | O9 Ia   |  4.38 |   0 | 1900 | -7.01 |
       | \zeta Ori    | O9.7 I  |  2.35 |   0 |  225 | -4.41 |
       | Rigel    | B8 I    |  0.20 |   0 |  260 | -6.87 |
       #+TBLFM: $6=$3 - 0.2 $4 - (5 log10($5) - 5) ;f2
     - Absolute magnitudes are calculated assuming A_H = 0.2 A_V and D = 400 pc
       + Distance modulus: 5 log10(D) - 5 = 8.01
     - So it seems -4 (early O) to -1.5 (mid-B) is a reasonable spread for the H-band absolute magnitude for MS stars
       + So that is exactly a factor of 10 in H-band luminosity, which seems reasonable
         + We show below that F_H \sim F_bol^0.5, so this is a factor of 100 in total luminosity
       + Say -2 on average (around B2)
     - Supergiants like \zeta Pup are brighter, reaching -4.69, or -6.87 for Rigel
       - In general, supergiants will have higher L_H at lower T_eff, since the bolometric luminosities are roughly constant
       - But the winds will either be roughly constant, or 
     - The peak in the H_0 histogram is around 9.5
       + So this implies distance modulus of 11.5, or D = 10**((11.5 + 5)/5) = 2 kpc, which is totally reasonable
     - The faintest sources have H_0 \approx 12, or distance modulus of 14
       + Implying D = D = 10**((14 + 5)/5) = 6.3 kpc
       + Note that there is a little clump at H_0 \approx 12 at cos(l) = 1, which may correspond to the Galactic center population!
         + Those sources may be slightly brighter than B2 stars
         + If we used -2.5 instead (B0), then we would get 8 kpc
     - Brightest sources have H_0 \approx 5, or distance modulus of 8
       + Implying D = 100 pc, which again is reasonable
     - Total spread due to luminosity spectral type can only be 2.5 mag or so
       + Say from 10,000 to 100,000 times Lsun
       + Total spread in distance can be 30 or so, which gives spread of 1000 in observed flux, or 7.5 in apparent magnitude
       + So conclusion is that the majority of the variation in H_0 should be due to variation in distance
     - Now consider effect on angular size
       + If all bow shocks have same physical size, then an increase by a factor of 10 in R_0 is a decrease by a factor of 10 in distance, which is a decrease of 5 in magnitude
       + This is exactly what is seen!
       + Do this with the constants, assume physical size of 0.1pc
         + R0 = (0.1/D) 206265
           + => D = 20626.5 / R0
         + H0 = MH0 + 5 log10(D) - 5
           + = (MH0 - 5) - 5 log10(R0) + 5 log10(20626.5)
           + = 16.57 + MH0 - 5 log10(R0)
     - But we get the same from variations in intrinsic luminosity
       + Because R_0 \propto \beta{}^{1/2}
       + And \beta ~ L
         + Assuming that
           1. Environment Momentum flux is constant on average
           2. Stellar wind momentum flux is constant fraction of radiative luminosity
     - But it seems that a better estimate is that "modified wind momentum" (Mdot V R^{1/2}) is proportional to L^1.88 approx (although this is only really valid above 200,000 Lsun - see Puls 1996)
       + So we need the R(L) relationship
       + Use Eker et al (2015)
         + L \sim M^2.726 for 7 < M < 32 in solar units
         + R \sim M^0.5 (Fig 7a) => R ~ L^0.18
           + Giving Mdot V ~ L^1.8
         + => T ~ M^a where a = (2.726 - 2 0.5) / 4  = 0.4315
           + Which is consistent with Fig 7b
           + And which means T \sim L^0.158
     - So if we take \beta ~ L^1.88 from above
       + Then bow shock R_0 ~ L^0.94
       + But how does M_H depend on L?
         + We are approx in the RJ tail, so L_\lambda ~ T R^2 whereas L_bol ~ T^4 R^2
         + Therefore F_H ~ L / T_eff^3
         + Taking T \sim L^0.158 from above
         + => F_H ~ L^0.526 or L ~ F_H^1.90
         + This explains why there is only a one order of magnitude in H-band luminosity over the OB stars (although for supergiants, this would no longer hold)
     - We plot the lines for a B2 star at a range of distances from 300 to 8000 pc
       + And that reproduces the linear trend very well
     - We also plot the line for a variety of stars at 2 kpc
       + This overpredicts the variation in R_0, possibly because in reality brighter stars are interacting with higher-momentum environments, which would stop R_0 from increasing so much
       + Explicitly calculate the slope of the line:
         + R_0 = (0.1 / 2000) 206265 (L_H / L_0 )^{3.4/2} = 10.31 (L_H / L_0 )^{1.7}
         + => log10(R_0) = 1.01 + 1.7 log10 (L_H / L_0)
         + => log10 (L_H / L_0) = 0.59 log10(R_0) - 0.59
         + M_H - M_0 = -2.5 log10 (L_H / L_0)
         + H_0 = M_H + (5 log10(2000) - 5) = M_H + 11.51
         + H_0 = M_0 + 11.51 - 2.5 log10 (L_H / L_0)
         + H_0 = 11.51 + M_0  - 1.49 log10(R_0) - 1.49
         + M_0 = -2, so
         + H_0 = 8.02 - 1.49 log10(R_0)
       + And it cannot explain all the variation in H_0, since for MS stars L_H ~ L^0.5
         + Although supergiants are not included, and they would go to bigger L_H values
         + From the above table, they have M_H in range -4 to -7, so up to 100 times brighter than the B2V stars
         + But they are very rare, so probably don't contribute greatly
     - [X] Maybe calculate R_0 assuming radiation pressure on dust grain
       - Calculate distance of closest approach for impact parameter b=0
       - Equation of motion:
         1. m a = \sigma (L/c) / (4 \pi r^2) = m v dv / dr
         2. \int_v0^0 v dv = A \int_\infty^r0 r^-2 dr
            - where A = \sigma L / 4\pi m c
         3. -v^2/2  = -A (1/r_0 - 0)
         4. r_0 = 2 A / v^2 = 2 \sigma L / 4\pi m v^2 c
       - Also we can write for grains of size a and density \rho_s:
         - m = 4\pi/3 \rho_s a^3
         - \sigma = Q \pi a^2
         - => \sigma/m = 3/4 Q / \rho_s a
       - E.g., with
         - \rho_s = 3 g/cm^3
         - a = 0.1 \micro{}m
         - L = 1e4 Lsun
         - v = 50 km/s
         - Q = 1
       - We get r_0 = 0.066 pc (L_4 / a_0.1 v_50^2)
         - This is remarkably close to the 0.1 pc that we had assumed
         - And note that the dependence on L is almost identical to the stellar wind case (which was also roughly linear)
         - But, the ambient density does not enter in this case
       - All this is assuming that the dust is uncoupled from the gas
         - If they are coupled, then each grain has to drag around 100 times its own mass in gas
         - Which will reduce the stagnation radius by a factor of 100
         - So it probably wouldn't be competitive with the hydrodynamic stagnaton radius

  2. Next highest correlation is A_K versus |b|, which is unsurprising: higher extinction closer to the Galactic plane
  3. Finally, there is a weak correlation of A_K with H_0, due to larger extinction at greater distances.  But the fact that it is so weak implies that the variation between different lines of sight is more important for determining A_K


#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  import json
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr
  from astropy.table import Table
  import astropy.units as u
  import astropy.coordinates as coord
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-pairplot.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')
  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  tab['R0_fit'][tab['R0_fit'] == 0.0] = np.nan

  tab['log10 R0'] = np.log10(tab['R0_fit'])


  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  plotvars = ['log10 R0', 'log10 |b|', 'cos(l)', 'Hmag', 'Ak']
  bad_rows = np.zeros((len(tab),), dtype=bool)
  clip_values = {
      'Hmag': [4.5, 12.0],
      'Ak': [0.0, 5.0],
      'log10 R0': [0.3, 1.8],
      'log10 |b|': [-2.0, 1.3],
  }
  for pvar in plotvars:
      bad_rows = bad_rows | ~np.isfinite(np.array(tab[pvar]))
      if pvar in clip_values:
          vmin, vmax = clip_values[pvar]
          bad_rows = bad_rows | (np.array(tab[pvar]) <= vmin) | (np.array(tab[pvar]) >= vmax) 
  bad_row_indices, = np.nonzero(bad_rows)
  tab.remove_rows(bad_row_indices)

  # Make column names that print nicely on the graph
  pretty_vars = [
      r"$\log_{10} (R_0, '')$",
      r'$\log_{10} (|b|,{}^\circ)$', r'$\cos(\ell)$',
      r'$H_0$ mag', r'$A_K$']
  for pvar, ppvar in zip(plotvars, pretty_vars):
      tab[pvar].name = ppvar

  df = tab.to_pandas().fillna(0)
  g = sns.PairGrid(df, vars=pretty_vars, size=1.5)
  g = g.map_upper(plt.scatter, marker='.', alpha=0.2, color='r')
  g = g.map_lower(sns.kdeplot, cmap="Purples_d", n_levels=10)
  g = g.map_diag(plt.hist)

  # Plot the line for size of a 0.1 pc bow shock at distances from 0.3 to 8 kpc
  Dgrid = np.logspace(2.5, 3.9)*u.pc
  R_phys = 0.1*u.pc
  R0 = (R_phys/Dgrid)*u.rad.to(u.arcsec)

  # Against apparent magnitude of an M_H = -2.0 star at the same distances
  MH0 = -2.0
  H = MH0 + (5*np.log10(Dgrid/u.pc) - 5)

  ax = g.axes[0, 3]
  ax.plot(H, np.log10(R0.value), ls='--', c='k', lw=2, alpha=0.8)
  axx = g.axes[3, 0]
  axx.plot(np.log10(R0.value), H, ls='--', c='k', lw=2, alpha=0.8)

  # Now do a varying H magnitude at a fixed distance of 2 kpc
  D0 = 2000*u.pc
  MHgrid = np.linspace(-3.6, -1.5)
  Hb = MHgrid + (5*np.log10(D0/u.pc) - 5)

  # H-band luminosity with respect to M_H = -2.0 star
  LH = 10**(0.4*(MH0 - MHgrid))
  # Bolometric luminosities for MS stars
  L = LH**1.90
  # Wind momentum relative to fiducial star with fixed environment momentum
  beta = L**1.80
  # Bow shock stand-off distance with physical radius ~ sqrt(beta)
  R0b = (R_phys*np.sqrt(beta)/D0)*u.rad.to(u.arcsec)

  # Plot as yellow dotted
  ax.plot(Hb, np.log10(R0b.value), ls=':', c='k', lw=2, alpha=0.8)
  axx.plot(np.log10(R0b.value), Hb, ls=':', c='k', lw=2, alpha=0.8)

  # Calculate Pearson correlations
  ytext = [None, 0.02, 0.02, 0.02, 0.7]
  savedict = {}
  for j, vy in enumerate(pretty_vars):
      for i, vx in enumerate(pretty_vars[:j]):
          r, p = pearsonr(df[vx], df[vy])
          savedict[f'{vx} vs. {vy}'] = {'r': r, 'p': p}
          s = f'$r = {r:.2f}$'
          if p > 0.001:
              s += '\n' + f'$p = {p:.4f}$'
          else:
              pexp = np.floor(np.log10(p))
              s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
          rax = g.axes[j, i]
          rax.text(0.95, ytext[j], s,
                   fontsize='xx-small',
                   bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
                   ha='right', va='bottom', transform=rax.transAxes)

  g.savefig(figfile)

  with open(figfile.replace('.pdf', '.json'), 'w') as f:
      json.dump(savedict, f, indent=4)


#+END_SRC

#+RESULTS:
[[file:mipsgal-pairplot.pdf]]

+ JSON file with the stats results: [[file:mipsgal-pairplot.json]]



*** Do all the statistical tests at once
+ This includes all the A/B tests on the MIPSGAL dataset
+ Plus intercomparison with Orion and RSG
+ And we do all the statistical tests we can think of
#+BEGIN_SRC python :return tabfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, mannwhitneyu, ttest_ind, levene
  import astropy.coordinates as coord
  from astropy.table import Table
  import astropy.units as u
  import json

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  def rank_biserial(a, b):
      U = mannwhitneyu(a, b, alternative='two-sided')
      rb = 1.0 - 2*U.statistic/(len(a)*len(b))
      return rb, U.pvalue

  class MyEncoder(json.JSONEncoder):
      def default(self, obj):
          if isinstance(obj, np.integer):
              return int(obj)
          elif isinstance(obj, np.floating):
              return float(obj)
          elif isinstance(obj, np.ndarray):
              return obj.tolist()
          else:
              return super(MyEncoder, self).default(obj)

  tabfile = 'mipsgal-all-stats.json'


  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  otab = Table.read('../LL-shapes-2017/ll-arcs-radii.tab', format='ascii.tab')
  ctab = Table.read('../LL-shapes-2017/rsg-arcs-radii.tab', format='ascii.tab')
  otab['Rc'] = otab['Rc out']
  otab['R90_asym'] = 2*otab['dR90']
  ctab['Rc'] = ctab['Rc out']
  ctab['R90_asym'] = 2*ctab['dR90']


  Ak_median = np.nanmedian(tab['Ak'][mgood])
  R0_median = np.nanmedian(tab[R0var][mgood])
  MH_median = np.nanmedian(tab['Hmag'][mgood])
  bmedian = np.nanmedian(tab['log10 |b|'][mgood])
  cosl_median = 0.8

  results = {}

  masks4tests = {
      'Environment: Facing': [
          tab['Env'] == 'I',
          (tab['Env'] == 'FH') | (tab['Env'] == 'FB')],
      'Environment: H II': [
          tab['Env'] == 'I',
          tab['Env'] == 'H'],
      'Single/Multiple source candidate': [
          tab['Unc'] != 'C',
          tab['Unc'] == 'C'],
      'With/without 8 micron': [
          tab['8um'] == 'Y',
          tab['8um'] != 'Y'],
      'Low/high extinction': [
          tab['Ak'] < Ak_median,
          tab['Ak'] >= Ak_median],
      'Low/high R0': [
          tab[R0var] < R0_median,
          tab[R0var] >= R0_median],
      'Faint/bright H magnitude': [
          tab['Hmag'] > MH_median,
          tab['Hmag'] <= MH_median],
      'Low/high |b|': [
          tab['log10 |b|'] < bmedian,
          tab['log10 |b|'] >= bmedian],
      'High/low cos(l)': [
          tab['cos(l)'] >= cosl_median,
          tab['cos(l)'] < cosl_median],
  }

  datasets4tests = {
      'OB vs Orion': [tab[mgood], otab],
      'OB vs RSG': [tab[mgood], ctab]
  }


  # First do the descriptive stats on the full sample of 3, 4, 5-star sources

  dep_vars = 'Rc', 'R90', 'Rc_sigma', 'R90_sigma', 'R90_asym'

  descriptive_stats = {
      'mean': np.nanmean,
      'median': np.nanmedian,
      'sigma': np.nanstd,
      'iqr': lambda x: np.diff(np.nanpercentile(x, [25, 75]))[0],
      'mad': lambda x: np.nanmedian(np.abs(x - np.nanmedian(x))),
      'n': len,
  }

  test_stats = {
      'Welch t-test for mean': lambda x, y: ttest_ind(x, y, equal_var=False),
      'Anderson-Darling': lambda x, y: anderson_ksamp([x, y], midrank=False)[::2],
      'Kolmogorov-Smirnov': ks_2samp, 
      'Rank biserial coefficient': rank_biserial,
      'Brown-Forsythe test for dispersion': levene,
  }

  results['Full sample'] = {
      v: {slabel: stat(tab[v][mgood])
          for slabel, stat in descriptive_stats.items()}
      for v in dep_vars}

  for mlabel, (m1, m2) in masks4tests.items():
      results[mlabel] = {
          v: {
              'Sample A': {
                  slabel: stat(tab[v][mgood & m1])
                  for slabel, stat in descriptive_stats.items()},
              'Sample B': {
                  slabel: stat(tab[v][mgood & m2])
                  for slabel, stat in descriptive_stats.items()},
              'A vs B Tests':{
                  tlabel: test(tab[v][mgood & m1], tab[v][mgood & m2])
                  for tlabel, test in test_stats.items()}
          } for v in dep_vars}

  # We only have a sub-set of the vars for the other datasets
  dep_vars = 'Rc', 'R90', 'R90_asym'
  for dlabel, (d1, d2) in datasets4tests.items():
      results[dlabel] = {
          v: {
              'Sample A': {
                  slabel: stat(d1[v])
                  for slabel, stat in descriptive_stats.items()},
              'Sample B': {
                  slabel: stat(d2[v])
                  for slabel, stat in descriptive_stats.items()},
              'A vs B Tests':{
                  tlabel: test(d1[v], d2[v])
                  for tlabel, test in test_stats.items()}
          } for v in dep_vars}

  with open(tabfile, 'w') as f:
      json.dump(results, f, indent=4, sort_keys=True, cls=MyEncoder)

#+END_SRC

#+RESULTS:
[[file:mipsgal-all-stats.json]]


*** Make a table of all the statistics
#+BEGIN_SRC python :return tabfile :results file
  import json
  import numpy as np
  from astropy.table import Table

  tabfile = 'mipsgal-summary-stats.tab'
  comparisons = json.load(open('mipsgal-all-stats.json'))

  cols = [
      'Comparison',
      'Variable',
      # Descriptive stats
      'mean A',
      'mean B',
      'sigma A',
      'sigma B',
      'delta A',
      'delta B',
      'sigtot A',
      'sigtot B',
      # Effect sizes
      'r_b',
      'd_c',
      'sig/tau',
      # p-values
      'A-D p',
      'r_b p',
      'B-F p',
  ]

  formats = {
      'Comparison': '{}',
      'Variable': '{}',
      # Descriptive stats
      'mean A': '{:.3f}',
      'mean B': '{:.3f}',
      'sigma A': '{:.3f}',
      'sigma B': '{:.3f}',
      'delta A': '{:.3f}',
      'delta B': '{:.3f}',
      'sigtot A': '{:.3f}',
      'sigtot B': '{:.3f}',
      # Effect sizes
      'r_b': '{:.3f}',
      'd_c': '{:.3f}',
      'sig/tau': '{:.3f}',
      # p-values
      'A-D p': '{:.3g}',
      'r_b p': '{:.3g}',
      'B-F p': '{:.3g}',
  }


  select_params = ['R90', 'Rc', 'R90_asym']

  default_delta = {
      'Sample A': {'mean': np.nan},
      'Sample B': {'mean': np.nan},
  }

  rows = []
  for comparison, params in comparisons.items():
      if comparison == 'Full sample':
          continue
      for param, data in params.items():
          assert 'Sample A' in data, f'{comparison} {param} {data}'
          if param not in select_params:
              continue
          sig_param = param + '_sigma'
          sdata = params.get(sig_param, default_delta)
          delta_A = sdata['Sample A']['mean']
          delta_B = sdata['Sample B']['mean']
          sigA = data['Sample A']['sigma']
          sigB = data['Sample B']['sigma']
          nA = data['Sample A']['n']
          nB = data['Sample B']['n']
          sig_pool = np.sqrt((nA*sigA**2 + nB*sigB**2)/(nA + nB))
          row = {
             'Comparison': comparison,
             'Variable': param,
             # Descriptive stats
             'mean A': data['Sample A']['mean'],
             'mean B': data['Sample B']['mean'],
             'sigma A': sigA,
             'sigma B': sigB,
             'delta A': delta_A,
             'delta B': delta_B,
             'sigtot A': sigA/np.sqrt(nA),
             'sigtot B': sigB/np.sqrt(nB),
             # Effect sizes
             'r_b': data['A vs B Tests']['Rank biserial coefficient'][0],
             'd_c': (data['Sample A']['mean'] - data['Sample B']['mean'])/sig_pool,
             'sig/tau': sigA / sigB,
             # p-values
             'A-D p': data['A vs B Tests']['Anderson-Darling'][1],
             'r_b p': data['A vs B Tests']['Rank biserial coefficient'][1],
             'B-F p': data['A vs B Tests']['Brown-Forsythe test for dispersion'][1],
          }
          rows.append(row)

  tab = Table(names=cols, rows=rows)

  tab.write(tabfile, format='ascii.tab', formats=formats)

#+END_SRC

#+RESULTS:
[[file:mipsgal-summary-stats.tab]]

*** Copy mipsgal figure files to paper folder
#+BEGIN_SRC sh :results output
  FIGFILES='mipsgal-r0-r0-plus-dPA-edited.pdf mipsgal-Rc-R90-zoom-annotated.pdf mipsgal-Rc-R90-thumbnails.pdf mipsgal-pairplot.pdf mipsgal-Rc-R90-Mag.pdf mipsgal-Rc-R90-R0.pdf mipsgal-Rc-R90-candidates.pdf mipsgal-Rc-R90-environment.pdf mipsgal-Rc-R90-vs-Orion.pdf mipsgal-Rc-R90-vs-Herschel.pdf p-value-histogram.pdf mipsgal-boxplot-Rc-R90-versus-R0.pdf mipsgal-boxplot-Rc-R90-versus-H0.pdf mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf'
  date
  pwd
  for f in $FIGFILES; do
      cp -av $f ../papers/Paper1/figs 
  done
#+END_SRC

#+RESULTS:
#+begin_example
Fri Apr 14 22:51:46 CDT 2017
/Users/will/Work/Bowshocks/Jorge/bowshock-shape/Stellar-Bowshocks-2017
mipsgal-r0-r0-plus-dPA-edited.pdf -> ../papers/Paper1/figs/mipsgal-r0-r0-plus-dPA-edited.pdf
mipsgal-Rc-R90-zoom-annotated.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-zoom-annotated.pdf
mipsgal-Rc-R90-thumbnails.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-thumbnails.pdf
mipsgal-pairplot.pdf -> ../papers/Paper1/figs/mipsgal-pairplot.pdf
mipsgal-Rc-R90-Mag.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-Mag.pdf
mipsgal-Rc-R90-R0.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-R0.pdf
mipsgal-Rc-R90-candidates.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-candidates.pdf
mipsgal-Rc-R90-environment.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-environment.pdf
mipsgal-Rc-R90-vs-Orion.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-vs-Orion.pdf
mipsgal-Rc-R90-vs-Herschel.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-vs-Herschel.pdf
p-value-histogram.pdf -> ../papers/Paper1/figs/p-value-histogram.pdf
mipsgal-boxplot-Rc-R90-versus-R0.pdf -> ../papers/Paper1/figs/mipsgal-boxplot-Rc-R90-versus-R0.pdf
mipsgal-boxplot-Rc-R90-versus-H0.pdf -> ../papers/Paper1/figs/mipsgal-boxplot-Rc-R90-versus-H0.pdf
mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf -> ../papers/Paper1/figs/mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf
#+end_example

Also, example objects for each star rating
| 3 star | 0503 |
| 4 star | 0014 |
| 5 star | 0018 |

Three consecutive arcs, all with similar values
| 3 star | 0633 |
| 4 star | 0634 |
| 5 star | 0635 |

Close to each other, and similar sizes
| 3 star | 0689 |
| 4 star | 0696 |
| 5 star | 0688 |

Another nice group of 3, all similar sizes
| 3 star | 0533 |
| 4 star | 0532 |
| 5 star | 0530 |

Close group of 3, but disparate sizes
| 3 star | 0528 |
| 4 star | 0521 |
| 5 star | 0527 |

This is the one I am tending towards - close together on the sky, clearly showing progression in quality, and with a variety of sizes
| 3 star | 0510 |
| 4 star | 0506 |
| 5 star | 0517 |


#+BEGIN_SRC sh :results output
  date
  pwd
  cp -av OB/MipsGal/0510-*.png ../papers/Paper1/figs/0510-3-star.png 
  cp -av OB/MipsGal/0506-*.png ../papers/Paper1/figs/0506-4-star.png 
  cp -av OB/MipsGal/0517-*.png ../papers/Paper1/figs/0517-5-star.png 
#+END_SRC

#+RESULTS:
: Mon Mar 20 19:04:51 CST 2017
: /Users/will/Work/Bowshocks/Jorge/bowshock-shape/Stellar-Bowshocks-2017
: OB/MipsGal/0510-G315.8313+00.1055-MG3160p005-multiplot.png -> ../papers/Paper1/figs/0510-3-star.png
: OB/MipsGal/0506-G314.6326+00.0995-MG3150p005-multiplot.png -> ../papers/Paper1/figs/0506-4-star.png
: OB/MipsGal/0517-G316.5611-00.3164-MG3170n005-multiplot.png -> ../papers/Paper1/figs/0517-5-star.png







*** Distribution of p-values
+ To make sure that we are not indulging in p-hacking
+ We can do a histogram of all the p-values

#+name: all-p-values
| Correlation     |         p |
|-----------------+-----------|
| Rc vs R0        |    0.0054 |
| R90 vs R0       |    0.0001 |
| Rc vs H         |    0.1229 |
| R90 vs H        |    0.0215 |
| Rc vs Facing    |      0.71 |
| Rc vs H II      |      0.50 |
| R90 vs Facing   |      0.60 |
| R90 vs H II     |      0.52 |
| Rc vs Confuse   |      1.00 |
| R90 vs Confuse  |      0.34 |
| Rc vs Herschel  |     0.074 |
| R90 vs Herschel |   0.00052 |
| Rc vs M42       |   0.00048 |
| R90 vs M42      | 0.0000105 |
| Rc vs 8 mic     |      0.82 |
| R90 vs 8 mic    |       0.6 |
| Rc vs AK        |      0.19 |
| R90 vs AK       |      0.63 |
| Rc vs b         |      0.19 |
| R90 vs b        |      0.31 |
| Rc vs cos(l)    |       1.0 |
| R90 vs cos(l)   |      0.36 |

# :return pvalues
#+header: :var tab=all-p-values
#+BEGIN_SRC python :return figfile :results file 
  import numpy as np
  import matplotlib.pyplot as plt
  import seaborn as sns
  sns.set_style('white')
  sns.set_color_codes('dark')
  figfile='p-value-histogram.pdf'
  pvalues = np.array([float(p) for s, p in tab])
  n = len(pvalues)
  fig, ax = plt.subplots(figsize=(6,3))
  x1, x2 = -5.0, 0.0
  sns.distplot(np.log10(pvalues), kde=False, rug=True,
               rug_kws={'height': 0.4/9.0},
               hist_kws={'range': [x1, x2]}, bins=18, ax=ax)
  x = np.linspace(x1, x2, 200)
  ax.plot(x, 9.0*10**x, c='r')
  xu = -0.6
  ax.annotate('uniform', (xu, 9.0*10**xu), color='r',
              xytext=(-5, 20), textcoords='offset points',
              ha='right', va='bottom', bbox={'fc': 'w', 'alpha': 0.7, 'ec': 'none'},
              arrowprops={'arrowstyle': '-|>', 'color': 'r'})

  for p0 in 0.001, 0.05:
      ax.axvspan(np.log10(p0), x2+0.05, color='k', alpha=0.05)
      ax.axvline(np.log10(p0), lw=2, ls='--', alpha=0.7, c='k')
  ax.set(xlim=[x1-0.1, x2+0.05], ylim=[-0.7, 9.0],
	 xlabel='$\log_{10}(p)$', ylabel='Number of correlations tested',
  )
  ax.text(np.log10(0.001), 6, '$p = 0.001$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  ax.text(np.log10(0.05), 6, '$p = 0.05$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  xa, xb = np.log10(0.001), np.log10(0.05)
  ax.annotate('significant', (xa, 7.5),
              xytext=(-10, 0), textcoords='offset points',
              ha='right', va='bottom')
  ax.annotate('marginally\nsignificant', (0.5*(xa+xb), 7.5),
              xytext=(0, 0), textcoords='offset points',
              ha='center', va='center')
  ax.annotate('non-significant', (xb, 7.5),
              xytext=(10, 0), textcoords='offset points',
              ha='left', va='bottom')
  sns.despine(ax=ax, trim=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:p-value-histogram.pdf]]


+ [2017-04-16 Sun] Try again with the values from astropy table

#+BEGIN_SRC python :return figfile :results file 
  import numpy as np
  from astropy.table import Table
  import matplotlib.pyplot as plt
  import seaborn as sns
  sns.set_style('white')
  sns.set_color_codes('dark')
  figfile='p-value-histogram-new.pdf'
  tab = Table.read('mipsgal-summary-stats.tab', format='ascii.tab')
  pvalues = np.concatenate([tab['r_b p'], tab['B-F p'], tab['A-D p']])
  n = len(pvalues)
  nsig = (pvalues < 0.001).sum()
  nn = n - nsig
  fig, ax = plt.subplots(figsize=(6,3.5))
  x1, x2 = -6.0, 0.0
  nbins = 18
  height = 500.0
  pvalues[pvalues < 10**x1] = 10**x1
  sns.distplot(np.log10(pvalues), kde=False, rug=True,
               rug_kws={'height': 0.05, 'lw': 0.5},
               hist_kws={'range': [x1, x2], 'bottom': 0.01}, bins=nbins, ax=ax)
  x = np.linspace(x1, x2, nbins)
  xc = 0.5*(x[1:] + x[:-1])
  pc = 10**x[1:] - 10**x[:-1]
  ax.plot(xc, nn*pc, c='r')
  xu = -0.6

  ax.annotate('uniform\n$p$ distribution', (xc[-7], nn*pc[-7]), color='r',
              xytext=(5, -20), textcoords='offset points',
              ha='left', va='top', bbox={'fc': 'w', 'alpha': 0.7, 'ec': 'none'},
              arrowprops={'arrowstyle': '-|>', 'color': 'r'})

  for p0 in 0.001, 0.05:
      ax.axvspan(np.log10(p0), x2+0.05, color='k', alpha=0.05)
      ax.axvline(np.log10(p0), lw=2, ls='--', alpha=0.7, c='k')
  ticklabels = [f'$10^{{{i}}}$' for i in range(-6, 1)]
  ticklabels[0] = r'$\leq 10^{-6}$'
  ax.set(xlim=[x1-0.1, x2+0.05], ylim=[0.005, height],
	 xticks=range(-6, 1),
	 xticklabels=ticklabels,
	 xlabel='$p$', ylabel='Number of correlations tested',
	 yscale='log',
  )
  ax.text(np.log10(0.001), 20, '$p = 0.001$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  ax.text(np.log10(0.05), 20, '$p = 0.05$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  xa, xb = np.log10(0.001), np.log10(0.05)
  ax.annotate('significant', (xa, 0.4*height),
              xytext=(-20, 0), textcoords='offset points',
              ha='right', va='bottom', fontsize='small')
  ax.annotate('marginally\nsignificant', (0.5*(xa+xb), 0.4*height),
              xytext=(0, 0), textcoords='offset points',
              ha='center', va='center', fontsize='small')
  ax.annotate('non-significant', (xb, 0.4*height),
              xytext=(5, 0), textcoords='offset points',
              ha='left', va='bottom', fontsize='small')
  sns.despine(ax=ax, trim=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:p-value-histogram-new.pdf]]


+ [ ] [2017-04-16 Sun] Try linear version again
+ Previously, linear version does not work because we didn't have enough samples
+ But now we have more if we use all the r_b and B--F p-values
#+BEGIN_SRC python :return figfile :results file 
  import numpy as np
  import matplotlib.pyplot as plt
  from astropy.table import Table
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')
  figfile='p-value-histogram-new-linear.pdf'
  tab = Table.read('mipsgal-summary-stats.tab', format='ascii.tab')
  pvalues = np.concatenate([tab['r_b p'], tab['B-F p']])

  n = len(pvalues)
  fig, ax = plt.subplots(figsize=(6,3))
  x1, x2 = 0.0, 1.0
  sns.distplot(pvalues, kde=False, rug=True,
               rug_kws={'height': 0.05},
               hist_kws={'range': [x1, x2]}, bins=10, ax=ax)
  x = np.linspace(x1, x2, 200)
  ax.plot(x, 2.0*x**0.0, c='r')
  ax.axvspan(0.05, x2, color='k', alpha=0.05)
  ax.axvline(0.05, lw=2, ls='--', alpha=0.7, c='k')
  ax.set(xlim=[x1, x2], ylim=[0.0, None],
	 xlabel='Significance level, $p$', 
     ylabel='Number of correlations tested',
  )
  ax.text(0.05, 1.5, '$p = 0.05$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  ax.annotate('significant', (0.05, 2),
              xytext=(-10, 0), textcoords='offset points',
              ha='right', va='bottom')
  ax.annotate('non-significant', (0.05, 2),
              xytext=(10, 0), textcoords='offset points',
              ha='left', va='bottom')
  sns.despine(ax=ax, trim=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:p-value-histogram-new-linear.pdf]]


**** Controlling the familywise error rate
+ This is the "multiple comparison" problem
  + Also known as Jelly Bean problem: https://xkcd.com/882/
+ We can use the Holm--Bonferroni method or the Holm--Šidák method to modify the confidence level, so as to maintain p=0.05 over all the tests
  + \cite{Holme:1979a}
+ \alpha = 0.05 is significance level
+ m = 22 is number of hypotheses
+ k is rank of p-value ordered from lowest to highest
+ Holm--Bonferroni compares each p-value agains  \alpha/(m + 1 - k)
  + And, once we have one p larger than this, discards that and all remaining ones as non-significant
+ Holm--Šidák uses 1 - (1-\alpha)^{1/(m + 1 - k)} instead
  + But it doesn't actually make a fat lot of difference
+ In fact, in our case we would get the same result from using \alpha/m for all comparisons
  + Which is the classical Bonferroni procedurew
+ Whichever way, it is only the first four hypotheses that make the cut.
+ But we can also use Benjamini & Hochberg (1995)
  + \cite{Benjamini:1995a}
  + Supposedly controls the False Discovery Rate (FDR)
  + The same as above, but comparing against k \alpha / m
  + This is slightly /softer/ and leads to null hypothesis rejection for the first 5 tests. 

| Correlation     |         p |  k | m + 1 - k |     HB |     HS |     BH |   |
|-----------------+-----------+----+-----------+--------+--------+--------+---|
| R90 vs M42      | 0.0000105 |  1 |        22 | 0.0023 | 0.0023 | 0.0023 | * |
| R90 vs R0       |    0.0001 |  2 |        21 | 0.0024 | 0.0024 | 0.0045 | * |
| Rc vs M42       |   0.00048 |  3 |        20 | 0.0025 | 0.0026 | 0.0068 | * |
| R90 vs Herschel |   0.00052 |  4 |        19 | 0.0026 | 0.0027 | 0.0091 | * |
| Rc vs R0        |    0.0054 |  5 |        18 | 0.0028 | 0.0028 | 0.0114 | x |
| R90 vs H        |    0.0215 |  6 |        17 | 0.0029 | 0.0030 | 0.0136 | . |
| Rc vs Herschel  |     0.074 |  7 |        16 | 0.0031 | 0.0032 | 0.0159 |   |
| Rc vs H         |    0.1229 |  8 |        15 | 0.0033 | 0.0034 | 0.0182 |   |
| Rc vs AK        |      0.19 |  9 |        14 | 0.0036 | 0.0037 | 0.0205 |   |
| Rc vs b         |      0.19 | 10 |        13 | 0.0038 | 0.0039 | 0.0227 |   |
| R90 vs b        |      0.31 | 11 |        12 | 0.0042 | 0.0043 | 0.0250 |   |
| R90 vs Confuse  |      0.34 | 12 |        11 | 0.0045 | 0.0047 | 0.0273 |   |
| R90 vs cos(l)   |      0.36 | 13 |        10 | 0.0050 | 0.0051 | 0.0295 |   |
| Rc vs H II      |      0.50 | 14 |         9 | 0.0056 | 0.0057 | 0.0318 |   |
| R90 vs H II     |      0.52 | 15 |         8 | 0.0063 | 0.0064 | 0.0341 |   |
| R90 vs Facing   |      0.60 | 16 |         7 | 0.0071 | 0.0073 | 0.0364 |   |
| R90 vs 8 mic    |       0.6 | 17 |         6 | 0.0083 | 0.0085 | 0.0386 |   |
| R90 vs AK       |      0.63 | 18 |         5 | 0.0100 | 0.0102 | 0.0409 |   |
| Rc vs Facing    |      0.71 | 19 |         4 | 0.0125 | 0.0127 | 0.0432 |   |
| Rc vs 8 mic     |      0.82 | 20 |         3 | 0.0167 | 0.0170 | 0.0455 |   |
| Rc vs Confuse   |      1.00 | 21 |         2 | 0.0250 | 0.0253 | 0.0477 |   |
| Rc vs cos(l)    |       1.0 | 22 |         1 | 0.0500 | 0.0500 | 0.0500 |   |
#+TBLFM: $5=0.05/$4;f4::$6=1 - (1-0.05)**(1/($4));f4::$7=0.05 $3/22 ;f4


**** Dealing with "the error of the transposed conditional"
:PROPERTIES:
:TABLE_EXPORT_FILE: p-values-type-I-rate
:END:

+ The p-value gives 
  #+BEGIN_QUOTE
  The probability of finding a difference between two populations as large (or larger) than observed *if* there is no difference in the underlying distribution from which the two populations are drawn (the null hypothesis).
  #+END_QUOTE
+ The error lies in transposing that to
  #+BEGIN_QUOTE
  The probability that the null hypothesis is true *given* the observations.  That is, the probability of a /false positive/ or a /Type I error/. 
  #+END_QUOTE
+ This is discussed in detail in Colquhoun (2014)
  + \cite{Colquhoun:2014a}
+ Se also
  + \cite{Sellke:2001a}
  + Type I error probability \alpha from their eq (3) is given in table below
  + This is technically a lower bound on \alpha, which given by 
    \[
    \alpha(p) = \bigg[ 1 - \big(e p \ln p\big)^{-1} \bigg]^{-1}
    \]
  + But only when p < 1/e = 0.3679
+ One way of getting from one to the other is via Bayes' theorem
  + But that requires a prior (probability of hypothesis, independent of the data), which may be hard to estimate
+ Alternatively, by taking a more stringent significance threshold (e.g, p = 0.001), one can reduce the Type I error rate to about 0.05, regardless of the prior distribution
+ In general, we need to make a qualitative balance between:
  + Type I errors: false positives, thinking we have found something that is not really there
  + Type II errors: false negatives, failing to find a real effect due to insufficient /power/ in our methods
+ By decreasing our significance threshold from 0.05 to 0.001, we decrease the Type I error rate, but we have reduced the /statistical power/, so we will /increase/ the Type II error rate
  + Especially for effect sizes smaller than the widths of the distributions
+ Then there are Type III errors:
  + "correctly rejecting the null hypothesis for the wrong reason"
  + \cite{Mosteller:1948a}
  + Although, when I look at this in detail, it is more specific and less relevant than I initially thought

#+name: error-rates
| Correlation     |         p |      \alpha |   |
|-----------------+-----------+--------+---|
| Rc vs R0        |    0.0054 | 0.0712 | . |
| R90 vs R0       |    0.0001 | 0.0025 | * |
| Rc vs H         |    0.1229 | 0.4119 |   |
| R90 vs H        |    0.0215 | 0.1833 | . |
| Rc vs Facing    |      0.71 |      1 |   |
| Rc vs H II      |      0.50 |      1 |   |
| R90 vs Facing   |      0.60 |      1 |   |
| R90 vs H II     |      0.52 |      1 |   |
| Rc vs Confuse   |      1.00 |      1 |   |
| R90 vs Confuse  |      0.34 | 0.4993 |   |
| Rc vs Herschel  |     0.074 | 0.3437 |   |
| R90 vs Herschel |   0.00052 | 0.0106 | * |
| Rc vs M42       |   0.00048 | 0.0099 | * |
| R90 vs M42      | 0.0000105 | 0.0003 | * |
| Rc vs 8 mic     |      0.82 |      1 |   |
| R90 vs 8 mic    |       0.6 |      1 |   |
| Rc vs AK        |      0.19 | 0.4617 |   |
| R90 vs AK       |      0.63 |      1 |   |
| Rc vs b         |      0.19 | 0.4617 |   |
| R90 vs b        |      0.31 | 0.4967 |   |
| Rc vs cos(l)    |      1.00 |      1 |   |
| R90 vs cos(l)   |      0.36 | 0.4999 |   |
#+TBLFM: $3=$2 < exp(-1) ? 1/(1+1/(-exp(1) $2 log($2))) : 1 ;f4


|   C | \xi=0.1 |   | \xi=0.5 |   |  \xi=1 |   |
|-----+-------+---+-------+---+------+---|
| 0.0 |  1.00 |   |  1.00 |   | 1.00 |   |
| 0.1 |  0.21 |   |  0.68 |   | 0.90 |   |
| 0.2 |  0.15 | . |  0.55 |   | 0.80 |   |
| 0.3 |  0.11 |   |  0.45 |   | 0.70 |   |
| 0.4 |  0.09 |   |  0.37 | . | 0.60 |   |
| 0.5 |  0.07 |   |  0.29 |   | 0.50 | . |
| 0.6 |  0.05 |   |  0.23 |   | 0.40 |   |
| 0.7 |  0.04 |   |  0.16 |   | 0.30 |   |
| 0.8 |  0.02 |   |  0.11 |   | 0.20 |   |
| 0.9 |  0.01 |   |  0.05 |   | 0.10 |   |
|  1. |  0.00 |   |  0.00 |   | 0.00 |   |
#+TBLFM: $2=1 - $1**0.1;f2::$4=1 - $1**0.5;f2::$6=1 - $1;f2::


**** TODO False discovery rate revisited [2017-04-07 Fri]
+ Colquhoun uses "False discovery rate" to mean the probability of Type I error (given the observations)
+ There are some extensive discussions:
  + In discussions after [[https://errorstatistics.com/2015/03/16/stephen-senn-the-pathetic-p-value-guest-post/][this blog post]]
  + And in [[http://stats.stackexchange.com/questions/143325/confusion-with-false-discovery-rate-and-multiple-testing-on-colquhoun-2014/146405#146405][this stack exchange question]]
+ In both cases Colquhoun joins in
+ And there is a lot of push-back against his paper
+ Some of the anti-Colquhoun points made are
  1. That he misuses the term "false discovery rate" FDR when he really means "false discovery proportion" FDP, as defined by Benjamini-Hochberg
     - This point is made by Bonferroni in a stack exchage comment!
  2. That Colquhoun is assuming point nulls and two-sided tests, whereas in practice people often use composite nulls and one-sided tests
     - Although everyone seems to agree that most papers fail to be explicit about it
     - A point null is something like "there is no difference", or "parameters are uncorrelated"
     - A composite null can be something like "A is no better than B", that is, "difference is less than or equal to zero"
  3. That his "FDP \ge 30% for p < 0.05" is not as watertight as he thinks
     - It would be smaller if the prior probability of the null were < 50%
       + But he rebuts this by mocking the idea that we should presuppose the truth of the hypothesis we are testing
       + I'm not sure what I think of this - certainly in some cases we may have good external grounds for thinking that the null is not true
       + But he is right that it would be odd to be testing /only/ hypotheses that we are already convinced of
     - Supposedly things are different with one-sided tests and composite nulls, but I haven't really looked into this (see below)
+ Further info on this
  + Casella & Berger (1987) "Reconciling bayesian and frequentist evidence in the one-sided testing problem"
  + This argues a counterpoint to Berger & Sellke (1987), which was the ur-paper for Sellke, Bayarri, & Berger (2001) that gives the "callibration" of p-values
  + Note that these are two different Bergers!
    1. James O. Berger, who works with Sellke
    2. Roger L. Berger, who works with Casella
  + So, Casella & Berger consider 1-sided tests between two "diffuse" hypothesese, instead of the 2-sided test of a point hypothesis pace Berger & Sellke
    + They find that the posterior probability of H_0 (which is the false discovery proportion) is no higher than p in this case
    + Which is very different from Berger & Sellke
    + They suggest that the problem lies in having a point null, so that the (supposedly fair) prior is a "point mass" of 0.5 at H_0 and the other 0.5 spread over H_1.  They think that this is not an "impartial" prior, but is rather heavily biased in favour of H_0
+ The HEP point of view
  + Excellent review paper: Cousins (2017) "The Jeffreys--Lindley paradox and discovery criteria in high energy physics"
  + Jeffreys--Lindley paradox is that we can have a small p, which disfavours the null hypothesis H_0 in frequentist framework (small likelihood ratio), but if n is sufficiently large, then the Bayes Factor will favour H_0
    + This is for simple-vs-composite hypothesis testing
    + And is because \lambda \propto (\sigma_tot/\tau) BF
    + Where \lambda = L(\theta_0) / L(\hat{\theta}) is ratio of likelihood of \theta_0 under H_0 (which is a bit like p, but with the pdf instead of cdf) and L(\hat{\theta}) is maximum likelihood of \theta under H_1
    + And \sigma_tot = \sigma/N^{1/2} is the std of the observed sample mean if \sigma^2 is the population variance
    + And \tau is the scale of the prior pdf for H_1
  + It turns out that the false-positive Type I error rate \alpha is more usually defined as the /probability of wrongly rejecting H_0 when it is true/, which means that it is equal to the p value
    + So this is very different from how Sellke (2001) use it, which is /probability of H_0 given the data/, or the "posterior probability of H_0": Pr(H_0 | x)
    + So I should probably not use \alpha in this way, since it is a bit non-standard
  + Interesting history of 5-\sigma criterion (p = 3e-7 !!!):
    + This arose from observations in 1960s of resonances associated with new particles
    + Partly a way of mitigating the "multiple trials factor", which in HEP seems to be called the /look elsewhere effect/
    + And partly to offset poorly understood "systematic effects"
    + Was mainly practical, in the sense that empirically it was found that 3-\sigma and 4-\sigma discoveries tended to go away as more data was accumulated
    + There is even a short paper by Louis Lyons (2013) on it
  + One strategy for dealing with the look elsewhere effect is given in Gross & Vitells (2010), while another is given in Algeri & van Dyk (2017)
    + These are both a lot more complicated than tha Bonferroni correction
  + Hierarchy of scales that give rise to the Jeffreys--Lindley paradox
    + \tau \gg \sigma_tot \gg \epsilon
    + \tau and \sigma_tot are defined above (H_1 prior scale and evidence scale)
    + \epsilon is the scale of H_0, which \to 0 for a point hypothesis
  + So the factor (\sigma_tot/\tau) is called the /Ockham factor/
    + It can become very small for large N
  + In HEP there is often a high degree of belief in the null hypothesis
+ So there is a big fight among
  1. Those who don't like p-values and think we should report posterior probabilities instead
     - For example, [[http://www.fharrell.com/2017/02/a-litany-of-problems-with-p-values.html][Frank Harrell in this blog post]]
  2. Those who say this is confusing things and that \alpha should always mean the significance level for the likelihood integral.  And that there is no problem with p-values per se, just with people abusing them
     - For example, anything by [[https://errorstatistics.com][Deborah Mayo]]


**** Problems with the median split
+ Cautionary quote from \cite{Ruscio:2008a}
  #+BEGIN_QUOTE
  The methodological literature consistently cautions against artificially dichotomizing continuous variables, and the consequences of this practice on measures of effect size will not be considered further.
  #+END_QUOTE
+ See also \cite{MacCallum:2002a}
  #+BEGIN_QUOTE
  The authors examine the practice of dichotomization of quantitative measures, wherein relationships among variables are examined after 1 or more variables have been converted to dichotomous variables by splitting the sample at some point on the scale(s) of measurement. A common form of dichotomization is the median split, where the independent variable is split at the median to form high and low groups, which are then compared with respect to their means on the dependent variable. The consequences of dichotomization for measurement and statistical analyses are illustrated and discussed. The use of dichotomization in practice is described, and justifications that are offered for such usage are examined. The authors present the case that dichotomization is rarely defensible and often will yield misleading results.
  #+END_QUOTE
+ And finally \cite{Streiner:2002a}
  #+BEGIN_QUOTE
  So. in conclusion, the one word of advice about turning continuous variables into dichotomies is—don't!
  #+END_QUOTE
+ *CONCLUSION*
  + We really ought to do the Pearson r for all the continuous variables, to check that the p-values from those are comparable to the Anderson-Darling ones
  + The main problem with the median split is that we are throwing away information. 

**** TODO Statistical power, Type II errors (\beta), and effect size
+ [X] Get the McGrath & Meyer (2006) paper
  + Discusses differences between r and d as measures of effect size for two-sample tests
  + But only interested in changes in the mean
+ [ ] Calculate effect sizes for all our tests
  + Cohen's d for the dichotomous tests
    + Note that pooled std dev requires care to calculate
    + https://en.wikipedia.org/wiki/Pooled_variance
    + And [[http://stats.stackexchange.com/questions/43159/how-to-calculate-pooled-variance-of-two-groups-given-known-group-variances-mean][this]] stack exchange answer
  + [ ] Or we can use the rank biserial correlation coefficient that we calculated from the Mann-Whitney U statistic
  + And we can use sigma ratio to give heteroscedastic effect size 
  + Pearson r for the continuous-continuous (but we already have this)
  + Also https://www.psychometrica.de/effect_size.html has lots of javascript calculators for transorming between different sorts of effect sizes
+ [X] Find p value for Pearson r tests (such as in the pair plot)
+ [ ] Do Pearson r for all the continuous variables against Rc and R90, and compare the p-values with those from A-D
***** Effect size for changes in dispersion
+ There is a paper by Best (1994) that talks about a "partition-of-\chi^2" test that treats location and spread separately
  + This cites a previous paper by Nair (1986)
  + And that has a citation of Mood (1954), who has what may be even better, so we look at that next
+ Mood has various tests, but including:
  #+BEGIN_QUOTE
  square rank test for dispersion
  #+END_QUOTE
  which looks worth investigating
+ There are more tests discussed in "Rank Tests of Dispersion" by Moses (1963)
  + He finds that most go wrong when the means or medians are not equal
+ Further analysis is done by Fligner & Killeen (1976) "Distribution-Free Two-Sample Tests for Scale"
  + They assume equal medians
  + They have modified versions of three previous tests
    1. Ansari-Bradley
    2. Mood
    3. Klotz
  + They spend most time on the Mood analog
  + For an effect size, they use \sigma/\tau, which is the ratio of the dispersions of the underlying distribution functions for the two samples
+ Now I have discovered more tests for equality of dispersion
  + [[https://en.wikipedia.org/wiki/F-test_of_equality_of_variances][F-test_of_equality_of_variances]] is for Gaussian distributions, and it is supposedly very sensitive to the normality assumption so needs to be used with care
    + The test statistic is just the ratio of variances between the two groups
      + It's distribution should follow the central F-distribution if the population variances are in fact equal.  For large N, this just looks like a slightly skew gaussian, centered on 1
      + If they are not equal, then the distribution of the test statistic is a non-central F-distribution, that will center on the the true ratio
    + A version of this for the k-sample case is Hartley's test, which simply looks at the ratio of group variances between the largest and smallest
  + There are other, more robust tests, of which the best seems to be the [[https://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test][Brown–Forsythe_test]]
    + Brown & Forsyth (1974)
  + But the only one I can find a python routine for is [[https://en.wikipedia.org/wiki/Levene%2527s_test][Levene's test]]
    + See also this [[http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm][NIST page]]
    + Implemented in =scipy.stats.levene=
    + Has the advantage that there are three different variants, which use different measures of the "location" (mean, median, or trimmed mean), which are better suited to different sorts of distributions
    + So, if we use the median option, then this /is/ the Brown-Forsythe test
    + In Brown & Forsyth (1974), the three options are called W_0, W_50, and W_10
      + W_0 (mean) is the original Levine
      + W_50 (median) is B--F, and is recommended for skewed distros
      + W_10 (trimmed) is recommended for heavy-tailed distros
+ Brown & Forsyth (1974) Table 1 gives power estimates for various tests at the \alpha = 0.05 level
  + By which they mean the p-value threshold
  + Numbers are expressed as percentages
  + For zero effect size (1:1 variances), these /ought/ to give p = \alpha = 5%
    + But the parametric tests, e.g., F-test, give much larger values when the distros are non-gaussian
  + With N=40 in each sample, we only have power of about 40% for 2:1 variances, or 80% for 4:1 variances (this is using W_50 or W_10, as appropriate)
  + Presumably, this would improve with larger N
  + Unfortunately, there is no estimate for smaller values of \alpha than 0.05

*** Comparison with the Orion Nebula bow shocks

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-vs-Orion.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  otab = Table.read('../LL-shapes-2017/ll-arcs-radii.tab', format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 5.5], [0.0, 5.5], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  R0_median = np.nanmedian(tab['R0_fit'][mgood])

  myes = tab['R0'] >= R0_median
  mno = tab['R0'] < R0_median

  masks = mgood, 
  shades = True, 
  alphas = 0.5, 
  cmaps = 'Purples', 
  gammas = 0.5, 
  lss = None, 

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.4],
                  bw=(0.15, 0.1),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  # masks5 = m5, 
  # colors = 'purple', 
  # alphas = 0.8, 
  # labels = 'MIPSGAL',

  ax.plot(tab['Rc'][m5], tab['R90'][m5], 
          'o', ms=4, alpha=0.5, c='purple', label='MIPSGAL arcs')
  ax.plot(otab['Rc out'], otab['R90'], 
          'o', ms=7, alpha=0.8, c='g', mec='w', mew=1, label='M42 arcs')

  ax.legend(frameon=True, loc='lower right', title='')

  Rmax = 9.0

  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, Rmax], ylim=[0.0, Rmax],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.4
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  colors = 'purple', 'g'
  alphas = 0.8, 0.8
  labels = 'MIPSGAL', 'M42'

  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      datasets = tab['Rc'][m], otab['Rc out']
      for data, c, axx in zip(datasets, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(data, bins=16, hist_kws={'range': [0.0, Rmax]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.5f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, Rmax], xticks=[0, 2, 4, 6, 8])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      datasets = tab['R90'][m], otab['R90']
      for data, c, axx in zip(datasets, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(data, bins=16, hist_kws={'range': [0.0, Rmax]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.5f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, Rmax], xticks=[0, 2, 4, 6, 8])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-vs-Orion.pdf]]


*** Comparison with the Herschel AGB/RSG sources

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-vs-Herschel.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  otab = Table.read('../LL-shapes-2017/rsg-arcs-radii.tab', format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 2.6], [0.0, 2.6], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  R0_median = np.nanmedian(tab['R0_fit'][mgood])

  myes = tab['R0'] >= R0_median
  mno = tab['R0'] < R0_median

  masks = mgood, 
  shades = True, 
  alphas = 0.5, 
  cmaps = 'Purples', 
  gammas = 0.5, 
  lss = None, 

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.4],
                  bw=(0.15, 0.1),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  # masks5 = m5, 
  # colors = 'purple', 
  # alphas = 0.8, 
  # labels = 'MIPSGAL',

  ax.plot(tab['Rc'][m5], tab['R90'][m5], 
          'o', ms=4, alpha=0.5, c='purple', label='MIPSGAL arcs')
  ax.plot(otab['Rc out'], otab['R90'], 
          'o', ms=7, alpha=0.8, c='r', mec='w', mew=1, label='Herschel arcs')

  ax.legend(frameon=True, loc='lower right', title='')

  Rmax = 4.0

  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, Rmax], ylim=[0.0, Rmax],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      xticks=[0, 1, 2, 3, 4], yticks=[0, 1, 2, 3, 4], 
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      )


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.4
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  colors = 'purple', 'r'
  alphas = 0.8, 0.8
  labels = 'MIPSGAL', 'M42'

  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      datasets = tab['Rc'][m], otab['Rc out']
      for data, c, axx in zip(datasets, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(data, bins=16, hist_kws={'range': [0.0, Rmax]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.3f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, Rmax], xticks=[0, 1, 2, 3, 4])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      datasets = tab['R90'][m], otab['R90']
      for data, c, axx in zip(datasets, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(data, bins=16, hist_kws={'range': [0.0, Rmax]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, Rmax], xticks=[0, 1, 2, 3, 4])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-vs-Herschel.pdf]]


*** Where the figures are suposed to be (but they aren't)
http://iopscience.iop.org/0067-0049/227/2/18/suppdata/
http://iopscience.iop.org/0067-0049/227/2/18/media

** Tracing the shapes
*** OB stars
*** RSG stars (and AGB)
:PROPERTIES:
:ID:       94EECFDB-B61E-4242-89C2-09BD3B36D587
:END:
**** \alpha Orionis (Betelgeuse)
+ Press release image
  + [[file:RSG/Betelgeuse_Herschel_large.jpg]]
  + http://herschel.cf.ac.uk/results/betelgeuse
+ Original data from http://archives.esac.esa.int/hsa/whsa/
  + Use the most processed version: https://www.cosmos.esa.int/web/herschel/user-provided-data-products
  + [[file:RSG/AlphaOri-160_10_AFGL190.mod.fits]]
+ Put crosses on to trace the outer arc
  + file:RSG/Betelgeuse_Herschel-arcs.reg
+ Fit circle to the arc

#+BEGIN_SRC sh :results verbatim
cd RSG
python ../../read-shapes-LL/find-xy-shell.py alphaori --pa0 45
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
cd RSG
python ../../read-shapes-LL/fit-circle-shell.py alphaori --debug --thmax 75
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 115
    # variables        = 2
    chi-square         = 4833.978
    reduced chi-square = 42.779
    Akaike info crit   = 433.927
    Bayesian info crit = 439.417
[[Variables]]
    xc:  -136.600747 +/- 4.042615 (2.96%) (init=-328.3531)
    yc:  -68.7003769 +/- 2.189979 (3.19%) (init=-161.0606)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.788 
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 88.79302917,  7.40696111)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 88.75476522,  7.38787767)>
Separation star->center in arcsec:  152.90622356827168
sqrt(xc**2 + yc**2) =  152.903583849
#+end_example
**** Sources from Cox et al
+ From Fig 1, these look like good candidates
+ These are the ones that look like they will give a good chance of measuring R_c and R_90
  + Constitute 7 out of 22 "Type I" morphologies, which are the ones with bowshocks
  + So this is about 15% of the total sample
| Name      |       IRAS | Arc | PA (pm) | PA (R_0) |
|-----------+------------+-----+---------+---------|
| \alpha Ori     | 05524+0723 |  70 |    47.7 |      54 |
| UU Aur    | 06331+3829 |  70 |   170.4 |     200 |
| R Leo     | 09448+1139 |  70 |   112.3 |     117 |
| R Hya     | 13269-2301 |  70 |   313.7 |     284 |
| V1943 Sgr | 20038-2722 | 160 |     155 |     135 |
| X Pav     | 20075-6005 |  70 |    84.9 |      88 |
| \mu Cep     | 21419+5832 |  70 |   216.3 |      85 |
+ Position angles:
  + The PA (pm) column is the PA from proper motion
  + The PA (R_0) column is \theta in Cox et al table, which is PA of measured R_0
  + They are roughly similar, except for in \mu Cep
+ Arc tracing
  + Done at 70 micron in most of them, since higher resolution and arc is generally more prominent
  + Exception is V1943 Sgr, which was better at 160 micron because the arc is incomplete (and smaller radius) in 70 micron

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py uuaur --pa0 200
python $D/find-xy-shell.py rleo --pa0 120
python $D/find-xy-shell.py rhya --pa0 280
python $D/find-xy-shell.py v1943sgr --pa0 135
python $D/find-xy-shell.py xpav --pa0 90
python $D/find-xy-shell.py mucep --pa0 90
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/fit-circle-shell.py uuaur --debug --thmax 75 --savefig
python $D/fit-circle-shell.py rleo --debug --thmax 75 --savefig
python $D/fit-circle-shell.py rhya --debug --thmax 75 --savefig
python $D/fit-circle-shell.py v1943sgr --debug --thmax 75 --savefig
python $D/fit-circle-shell.py xpav --debug --thmax 75 --savefig
python $D/fit-circle-shell.py mucep --debug --thmax 75 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 32
    # variables        = 2
    chi-square         = 42.236
    reduced chi-square = 1.408
    Akaike info crit   = 12.881
    Bayesian info crit = 15.813
[[Variables]]
    xc:   15.0610640 +/- 1.100570 (7.31%) (init= 63.51735)
    yc:   25.5300293 +/- 0.918767 (3.60%) (init= 52.16668)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.851 
outer : 15.0610640641 25.5300293379 111.870661618
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 99.13680833,  38.44531944)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 99.14215003,  38.45241112)>
Separation star->center in arcsec:  29.641116012318466
sqrt(xc**2 + yc**2) =  29.6414920126
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 27
    # variables        = 2
    chi-square         = 104.474
    reduced chi-square = 4.179
    Akaike info crit   = 40.534
    Bayesian info crit = 43.125
[[Variables]]
    xc:  -33.3846142 +/- 2.578846 (7.72%) (init=-86.3434)
    yc:   9.37818363 +/- 1.079356 (11.51%) (init= 26.9824)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.698 
outer : -33.3846142656 9.37818363087 126.756157072
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 146.88944583,  11.42896667)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 146.87998473,  11.43157172)>
Separation star->center in arcsec:  34.67668601017268
sqrt(xc**2 + yc**2) =  34.6768337349
[[Fit Statistics]]
    # function evals   = 15
    # data points      = 24
    # variables        = 2
    chi-square         = 609.197
    reduced chi-square = 27.691
    Akaike info crit   = 81.618
    Bayesian info crit = 83.974
[[Variables]]
    xc:   110.175601 +/- 10.67015 (9.68%) (init= 90.24736)
    yc:  -23.0858829 +/- 6.627401 (28.71%) (init=-55.71501)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.895 
outer : 110.175601373 -23.0858829412 213.540750481
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.4279125, -23.28110833)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.46122962, -23.28752108)>
Separation star->center in arcsec:  112.56569836972328
sqrt(xc**2 + yc**2) =  112.568295399
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 11
    # variables        = 2
    chi-square         = 17.864
    reduced chi-square = 1.985
    Akaike info crit   = 9.334
    Bayesian info crit = 10.129
[[Variables]]
    xc:  -9.68883170 +/- 1.643640 (16.96%) (init=-38.86762)
    yc:   14.9640406 +/- 1.958355 (13.09%) (init= 50.65795)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.827 
outer : -9.68883170818 14.9640406645 83.2641253433
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 301.73027917, -27.22538889)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 301.72725251, -27.22123221)>
Separation star->center in arcsec:  17.826931215089093
sqrt(xc**2 + yc**2) =  17.8268329459
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 23
    # variables        = 2
    chi-square         = 11.868
    reduced chi-square = 0.565
    Akaike info crit   = -11.218
    Bayesian info crit = -8.947
[[Variables]]
    xc:  -22.2929159 +/- 1.108003 (4.97%) (init=-54.10835)
    yc:  -4.27263268 +/- 0.341913 (8.00%) (init=-10.72157)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.477 
outer : -22.2929159036 -4.27263268094 78.6385241074
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 302.94182917, -59.9371)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 302.92946771, -59.93828684)>
Separation star->center in arcsec:  22.698275321362722
sqrt(xc**2 + yc**2) =  22.6986671307
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 23
    # variables        = 2
    chi-square         = 143.971
    reduced chi-square = 6.856
    Akaike info crit   = 46.185
    Bayesian info crit = 48.456
[[Variables]]
    xc:  -29.4220193 +/- 3.508065 (11.92%) (init=-69.01557)
    yc:   8.35037470 +/- 1.062646 (12.73%) (init=-12.28705)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.392 
outer : -29.4220192961 8.35037470152 102.964786609
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 325.8768,  58.78037778)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 325.86103216,  58.78269733)>
Separation star->center in arcsec:  30.583102380367688
sqrt(xc**2 + yc**2) =  30.5840477556
#+end_example

R Hya looks like it would be better with --thmax 45
#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/fit-circle-shell.py rhya --debug --thmax 45 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 14
    # variables        = 2
    chi-square         = 26.774
    reduced chi-square = 2.231
    Akaike info crit   = 13.077
    Bayesian info crit = 14.355
[[Variables]]
    xc:   58.4657628 +/- 8.404392 (14.37%) (init= 90.24736)
    yc:  -15.0097612 +/- 4.656127 (31.02%) (init=-55.71501)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.950 
outer : 58.4657628622 -15.0097612186 166.101863129
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.4279125, -23.28110833)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.44559256, -23.28527771)>
Separation star->center in arcsec:  60.36084260447921
sqrt(xc**2 + yc**2) =  60.361729257
#+end_example

* Convert images to FITS
+ This has not been necessary yet, but may be needed for the O star arcs
#+BEGIN_SRC sh
python ~/Work/Image2FITS/image2fits.py RSG/Betelgeuse_Herschel_large.jpg
#+END_SRC

#+RESULTS:


* DONE Testing the angle functions in =find-xy-shell.py=
CLOSED: [2017-02-28 Tue 10:28]
+ There was a problem with the order of angles in \alpha Ori
  + Turns out it was simply due to failing to convert input degrees to radians for internal use
  + *Fixed* [2017-02-28 Tue]
+ This is the function that is used for sorting the angles:
#+name: find-th-order
#+BEGIN_SRC python
import numpy as np
def canonicalize(th, unit="radians"):
    """Fold an angle theta into the canonical range [-pi:pi]"""
    if unit == "radians":
        return ((th + np.pi) % (2*np.pi)) - np.pi
    elif unit == "degrees":
        return ((th + 180.0) % (360.0)) - 180.0
    else:
        raise NotImplementedError

def find_th_order(th, pa_ref, debug=True): 
    """Returns a sort order for a collection of angles theta
    
    Takes care to account for the wrap-around of angles by shifting
    the star-th1C vector to be at pi, so that all points are (with
    luck) in the range [0, 2 pi]

    """
    th1 = (canonicalize(th - pa_ref) + np.pi) % (2*np.pi)
    if debug: 
        print("Finding theta order:") 
        print("    th =", np.degrees(th)) 
        print("    pa_ref =", np.degrees(pa_ref)) 
        print("    th1 =", np.degrees(th1)) 
        print("    order =", th1.argsort()) 
    return th1.argsort()
#+END_SRC


#+BEGIN_SRC python :noweb yes :results output verbatim
<<find-th-order>>
th0 = np.radians(45.0)
th = np.radians([180, 45, 15, 90, 120, 310])
order = find_th_order(th, pa_ref=th0)

print(np.degrees(th[order]))
print(np.degrees(canonicalize(th[order] - th0)))

#+END_SRC

#+RESULTS:
: Finding theta order:
:     th = [ 180.   45.   15.   90.  120.  310.]
:     pa_ref = 45.0
:     th1 = [ 315.  180.  150.  225.  255.   85.]
:     order = [5 2 1 3 4 0]
: [ 310.   15.   45.   90.  120.  180.]
: [ -95.  -30.    0.   45.   75.  135.]

